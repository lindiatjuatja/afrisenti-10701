{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEkdLm_JF84s"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/afrisenti-semeval/afrisent-semeval-2023/main/afrisenti-logo.png\" width=\"30%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--lang_code\",\n",
    "#                         default='am',\n",
    "#                         type=str,\n",
    "#                         help=\"Valid codes: 'am', 'dz', 'ha', 'ig', 'ma', 'pcm', 'pt', 'sw', 'yo'\")\n",
    "# parser.add_argument(\"--use_en\", \n",
    "#                         action=\"store_true\",\n",
    "#                         help=\"Enable to use english data for zero shot rather than the original language codes\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# LANGUAGE_CODE = args.lang_code\n",
    "# USE_EN = args.use_en\n",
    "\n",
    "LANGUAGE_CODE = 'am'\n",
    "USE_EN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Code:  am\n"
     ]
    }
   ],
   "source": [
    "print(\"Language Code: \", LANGUAGE_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8QIl420aUM1O"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Please don not edit anything here\n",
    "languages = ['am', 'dz', 'ha', 'ig', 'ma', 'pcm', 'pt', 'sw', 'yo']\n",
    "\n",
    "colab = False\n",
    "\n",
    "\n",
    "TASK = 'SubtaskA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# if colab:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')\n",
    "#     proj_folder = '/content/drive/MyDrive'\n",
    "# else:\n",
    "#     proj_folder = os.getcwd()\n",
    "\n",
    "# %cd {proj_folder}\n",
    "\n",
    "\n",
    "# PROJECT_DIR = f'{proj_folder}/afrisent-semeval-2023'\n",
    "# if not os.path.isdir(PROJECT_DIR):\n",
    "#   %run Make_Datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME_OR_PATH = 'Davlan/afro-xlmr-mini'\n",
    "MODEL_NAME_OR_PATH = 'xlm-roberta-base'\n",
    "BATCH_SIZE = 16\n",
    "GRADIENT_ACCUMULATION_STEPS = 2\n",
    "LEARNING_RATE = 5e-5\n",
    "NUMBER_OF_TRAINING_EPOCHS = 5\n",
    "MAXIMUM_SEQUENCE_LENGTH = 128\n",
    "SAVE_STEPS = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sE22Nmnx9lf1"
   },
   "source": [
    "\n",
    "\n",
    "####Starter Code: Datasets, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 19003,
     "status": "ok",
     "timestamp": 1666879952672,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "ERP2sja3i3uQ",
    "outputId": "730084f3-6cde-4ef4-a638-861aed0addea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import warnings\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    PreTrainedTokenizerFast,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from tokenizers import SentencePieceBPETokenizer\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "from datasets import Features, Value, ClassLabel, load_dataset, Dataset\n",
    "\n",
    "require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/text-classification/requirements.txt\")\n",
    "\n",
    "np.random.seed(69)\n",
    "torch.manual_seed(420);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1666879952673,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "2k6XKSygMnT4",
    "outputId": "debd529a-c939-47d6-ae2c-60dd40430f4d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afrisent-semeval-2023\\\\SubtaskA\\\\train'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder = ''\n",
    "\n",
    "\n",
    "# if colab:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')\n",
    "#     proj_folder = '/content/drive/MyDrive'\n",
    "# else:\n",
    "#     proj_folder = os.getcwd()\n",
    "\n",
    "# %cd {proj_folder}\n",
    "\n",
    "\n",
    "# PROJECT_DIR = f'{proj_folder}/afrisent-semeval-2023'\n",
    "\n",
    "\n",
    "PROJECT_DIR = 'afrisent-semeval-2023'\n",
    "\n",
    "TRAINING_DATA_DIR = os.path.join(PROJECT_DIR, TASK, 'train')\n",
    "FORMATTED_TRAIN_DATA = os.path.join(TRAINING_DATA_DIR, 'formatted-train-data')\n",
    "\n",
    "TRAINING_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EJPw829sIRY3"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev-test', LANGUAGE_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1666879952911,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "ZSh2DwJzM_cI",
    "outputId": "326b1c0d-2cd5-4516-a142-7e0342714bd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGUAGE_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1666883839778,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "hZc-mzkXnhdF",
    "outputId": "06e5bc16-fd84-4c40-f720-3558328f4fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral', 'positive', 'negative']\n"
     ]
    }
   ],
   "source": [
    "# Set seed before initializing model.\n",
    "set_seed(42069)\n",
    "\n",
    "# obtain dev data\n",
    "df = pd.concat([pd.read_csv(DATA_DIR + '/dev.tsv', sep='\\t'), pd.read_csv(DATA_DIR + '/test.tsv', sep='\\t')])\n",
    "df = df.dropna()\n",
    "eval_dataset = Dataset.from_pandas(df)\n",
    "label_list = df['label'].unique().tolist()\n",
    "\n",
    "# Labels\n",
    "num_labels = len(label_list)\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using EN for zero shot\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# obtain train data\n",
    "if USE_EN:\n",
    "    print('Using EN for zero shot')\n",
    "    df = pd.read_csv('../adapter_notebooks/data/en_all.csv')[['text', 'labels']].rename(\n",
    "        columns={'labels':'label'})\n",
    "else:\n",
    "    lang_trains = []\n",
    "    for lang in languages:\n",
    "        if lang != LANGUAGE_CODE:\n",
    "            \n",
    "            lang_data_dir = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev-test', lang)\n",
    "            print('Adding', lang, 'to the training set')\n",
    "            lang_trains.append(pd.read_csv(lang_data_dir + '/train.tsv', sep='\\t'))\n",
    "    df = pd.concat(lang_trains)\n",
    "\n",
    "df = df.dropna()\n",
    "train_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Happy birthday Roman Abramovich. Treat yourself to a nice present in January. I think Radamel Falcao would fit the bill nicely.',\n",
       " 'label': 'positive'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9gxi4Ll-HFQ"
   },
   "source": [
    "####Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6173,
     "status": "ok",
     "timestamp": 1666883849304,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "pd_l2PG3nhiY",
    "outputId": "5753544f-0e2b-489c-edfc-1014449d4170"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH,\n",
    "    num_labels=num_labels,\n",
    "    cache_dir=None,\n",
    "    revision='main',\n",
    "    use_auth_token=None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH,\n",
    "    do_lower_case=None,\n",
    "    cache_dir=None,\n",
    "    use_fast=True,\n",
    "    revision='main',\n",
    "    use_auth_token=None,\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "    cache_dir=None,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    "    ignore_mismatched_sizes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1666883849305,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "slMaLbYvnHmP",
    "outputId": "7c6e8b47-3511-42b8-a689-317cd74f3190"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the datasets\n",
    "# Padding strategy\n",
    "padding = \"max_length\"\n",
    "\n",
    "\n",
    "label_to_id = None\n",
    "label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 21194,
     "status": "ok",
     "timestamp": 1666883870487,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "gKAQ2leboGN3",
    "outputId": "4d40c5b1-5009-4979-cf98-dfbbd898627e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d41e30bfa514e5fb46d6743356e7e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "1000 128\n",
      "721 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fd6e92e2324613a05b29ad9e851ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 128\n",
      "796 128\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    texts =(examples['text'],)\n",
    "    result = tokenizer(*texts, padding=padding, max_length=MAXIMUM_SEQUENCE_LENGTH, truncation=True)\n",
    "    print(len(result['input_ids']), len(result['input_ids'][0]))\n",
    "    \n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    \n",
    "    result['length'], result[\"tokenized\"] = [], []\n",
    "    for input_ids in result['input_ids']:\n",
    "        toks = tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=True)\n",
    "        result['length'].append(len(toks)+2)\n",
    "        result['tokenized'].append(' '.join(toks))\n",
    "    return result\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on train dataset\",\n",
    ")\n",
    "\n",
    "eval_dataset = eval_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on validation dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c661b30f9544877a8a9f21af7091a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask', 'length', 'tokenized'],\n",
       "    num_rows: 12721\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.filter(lambda a: len(a['input_ids']) <= MAXIMUM_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12721"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Happy birthday Roman Abramovich. Treat yourself to a nice present in January. I think Radamel Falcao would fit the bill nicely.',\n",
       " 'label': 1,\n",
       " 'input_ids': [0,\n",
       "  32506,\n",
       "  101207,\n",
       "  12610,\n",
       "  168044,\n",
       "  145739,\n",
       "  5,\n",
       "  4804,\n",
       "  257,\n",
       "  31949,\n",
       "  47,\n",
       "  10,\n",
       "  26267,\n",
       "  13379,\n",
       "  23,\n",
       "  18982,\n",
       "  5,\n",
       "  87,\n",
       "  5351,\n",
       "  95041,\n",
       "  7603,\n",
       "  22225,\n",
       "  123142,\n",
       "  2806,\n",
       "  11177,\n",
       "  70,\n",
       "  54727,\n",
       "  26267,\n",
       "  538,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'length': 31,\n",
       " 'tokenized': '▁Happy ▁birthday ▁Roman ▁Abram ovich . ▁Tre at ▁yourself ▁to ▁a ▁nice ▁present ▁in ▁January . ▁I ▁think ▁Rada mel ▁Fal cao ▁would ▁fit ▁the ▁bill ▁nice ly .'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '?? ?? ወርቅ እንደሚዘንብ ጠብቀህ ነበር ?? ለዛውም በስዕታት ውስጥ አየህ የዚህን ያህል ነው ሰውየውን የምትፈሩት....እኔ እኮ የማዝነው አንተን ፋለው ለሚያደርጉ ሰወች ነው ምስኪን ፂም!',\n",
       " 'label': 0,\n",
       " '__index_level_0__': 0,\n",
       " 'input_ids': [0,\n",
       "  24610,\n",
       "  24610,\n",
       "  6,\n",
       "  122109,\n",
       "  16678,\n",
       "  117225,\n",
       "  3833,\n",
       "  6,\n",
       "  91284,\n",
       "  4656,\n",
       "  4359,\n",
       "  25880,\n",
       "  24610,\n",
       "  2237,\n",
       "  13075,\n",
       "  63083,\n",
       "  48344,\n",
       "  16160,\n",
       "  53261,\n",
       "  5405,\n",
       "  2350,\n",
       "  5186,\n",
       "  4359,\n",
       "  144382,\n",
       "  548,\n",
       "  55620,\n",
       "  3053,\n",
       "  13698,\n",
       "  46506,\n",
       "  548,\n",
       "  59581,\n",
       "  6980,\n",
       "  63618,\n",
       "  5,\n",
       "  27,\n",
       "  81970,\n",
       "  158171,\n",
       "  22204,\n",
       "  7872,\n",
       "  26190,\n",
       "  97081,\n",
       "  548,\n",
       "  6,\n",
       "  8036,\n",
       "  13818,\n",
       "  2237,\n",
       "  52534,\n",
       "  92691,\n",
       "  12560,\n",
       "  5698,\n",
       "  5519,\n",
       "  3053,\n",
       "  61075,\n",
       "  29654,\n",
       "  548,\n",
       "  6,\n",
       "  244044,\n",
       "  816,\n",
       "  38,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'length': 61,\n",
       " 'tokenized': '▁?? ▁?? ▁ ወርቅ ▁እንደሚ ዘን ብ ▁ ጠብ ቀ ህ ▁ነበር ▁?? ▁ለ ዛ ውም ▁በስ ዕ ታት ▁ውስጥ ▁አ የ ህ ▁የዚህ ን ▁ያህል ▁ነው ▁ሰው የው ን ▁የምት ፈ ሩት . ... እኔ ▁እኮ ▁የማ ዝ ነው ▁አንተ ን ▁ ፋ ለው ▁ለ ሚያ ደርጉ ▁ሰ ወ ች ▁ነው ▁ምስ ኪ ን ▁ ፂ ም !'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1666883921333,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "6Hi6VwK5O1ve",
    "outputId": "1d30958b-4b3d-409f-e9c2-97f9fb4a07f5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'attention_mask', 'length', 'tokenized'],\n",
       "     num_rows: 12721\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask', 'length', 'tokenized'],\n",
       "     num_rows: 1796\n",
       " }))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6EnnkjSTKk4-"
   },
   "outputs": [],
   "source": [
    "train_text, train_labels = train_dataset['tokenized'], train_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tNt_9ZMsKnr8"
   },
   "outputs": [],
   "source": [
    "eval_text, eval_labels = eval_dataset['tokenized'], eval_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fi_pJl3N9RcT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text, tokenized, length. If text, tokenized, length are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Thomas\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 12721\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1990\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='1990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 251/1990 01:44 < 12:08, 2.39 it/s, Epoch 0.63/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the metric function\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "\n",
    "data_collator = default_data_collator\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args = TrainingArguments(\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        num_train_epochs=NUMBER_OF_TRAINING_EPOCHS,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "        output_dir='tmp_trainer',\n",
    "        save_steps=SAVE_STEPS,\n",
    "        overwrite_output_dir=True\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "# Training\n",
    "\n",
    "train_result = trainer.train(resume_from_checkpoint=None)\n",
    "metrics = train_result.metrics\n",
    "metrics[\"train_samples\"] = len(train_dataset) \n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "\n",
    "for key,value in metrics.items():\n",
    "    print(key, ':', value)\n",
    "\n",
    "splitted_A = os.path.join(PROJECT_DIR, 'SubtaskA', 'train', 'splitted-train-dev-test')\n",
    "\n",
    "try:\n",
    "    LANGUAGE_CODE\n",
    "except NameError:\n",
    "    LANGUAGE_CODE = 'combined'\n",
    "else:\n",
    "    pass\n",
    "\n",
    "data = []\n",
    "for lang in languages:\n",
    "    eval_path = os.path.join(splitted_A, lang)\n",
    "    df = pd.read_csv(eval_path + '/dev.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    lang_eval = Dataset.from_pandas(df)\n",
    "    lang_eval = lang_eval.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on validation dataset\",\n",
    "    )\n",
    "\n",
    "    predictions, labels, metrics = trainer.predict(lang_eval, metric_key_prefix=\"eval\")\n",
    "\n",
    "    if LANGUAGE_CODE == lang:\n",
    "        f1 = (f1_score(labels, np.argmax(predictions, axis=1), average='weighted'))\n",
    "        bal_acc = balanced_accuracy_score( labels, np.argmax(predictions, axis=1))\n",
    "\n",
    "    data.append([LANGUAGE_CODE, lang, str(list(predictions)), str(list(labels))])\n",
    "df = pd.DataFrame(data, columns=['source', 'target', 'predictions', 'labels'])\n",
    "df.to_csv(f'{LANGUAGE_CODE}_preds.csv', index=False)\n",
    "\n",
    "\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n",
    "print(f\"f1 score: {f1:.3}, balanced acc: {bal_acc:.3}\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# %cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev-test', LANGUAGE_CODE)\n",
    "# OUTPUT_DIR = os.path.join(PROJECT_DIR, 'models', LANGUAGE_CODE + '_no_test')\n",
    "# kinya = 'jean-paul/KinyaBERT-small'\n",
    "\n",
    "# !python starter_kit/run_textclass.py \\\n",
    "#   --model_name_or_path {kinya} \\\n",
    "#   --data_dir {DATA_DIR} \\\n",
    "#   --do_train \\\n",
    "#   --do_eval \\\n",
    "#   --per_device_train_batch_size {BATCH_SIZE} \\\n",
    "#   --learning_rate {MAXIMUM_SEQUENCE_LENGTH} \\\n",
    "#   --num_train_epochs {NUMBER_OF_TRAINING_EPOCHS} \\\n",
    "#   --max_seq_length {MAXIMUM_SEQUENCE_LENGTH} \\\n",
    "#   --output_dir {'tmp_trainer'} \\\n",
    "#   --save_steps {SAVE_STEPS} \\\n",
    "#   --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d203a7fbe37afbb990fedfc21c321928443618f3d7b991e0237ff71906aa031f"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "008a7cb40017467b8d4450e52e0c3ec5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2691cee6ebda4659afdc7afc3d7c3ccf",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d96193cb0ef436987f37d611e0c3c23",
      "value": 9
     }
    },
    "01bbb58eeced4ed4920756d513870c5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08e3f965a5ea4b338aba411dbb969ec6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c8da5d1f22f4f2990196f1d1164dc72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1193886e44d94cc9927d05680e26348d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edd1fc29c36a4beda3528a5b962d5d4e",
      "placeholder": "​",
      "style": "IPY_MODEL_508778f87d1a4733a86bc7466ce6c689",
      "value": " 9/10 [00:18&lt;00:01,  1.89s/ba]"
     }
    },
    "1d96193cb0ef436987f37d611e0c3c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2048f8794fef499cb0757fad16437a92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c8da5d1f22f4f2990196f1d1164dc72",
      "placeholder": "​",
      "style": "IPY_MODEL_47c11996d2f142779998e1ce52519e62",
      "value": " 1/2 [00:02&lt;00:01,  1.86s/ba]"
     }
    },
    "2691cee6ebda4659afdc7afc3d7c3ccf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "426e41f07cb145408a12146dff293ad6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b31b9c1562a4505bd84039e344eb03a",
      "placeholder": "​",
      "style": "IPY_MODEL_ac7711f32d374b74b6f7949db6d2cb94",
      "value": "Running tokenizer on validation dataset:  50%"
     }
    },
    "47c11996d2f142779998e1ce52519e62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b31b9c1562a4505bd84039e344eb03a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e6edbccc9224ba89714e6d0e67fe76e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aafb2c69887549648e9c7044d6a344f3",
       "IPY_MODEL_008a7cb40017467b8d4450e52e0c3ec5",
       "IPY_MODEL_1193886e44d94cc9927d05680e26348d"
      ],
      "layout": "IPY_MODEL_01bbb58eeced4ed4920756d513870c5f"
     }
    },
    "508778f87d1a4733a86bc7466ce6c689": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e01536f748a4689b0c1ab32258b0161": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "865bc4814f3742cdb1d2230f141a8e72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e01536f748a4689b0c1ab32258b0161",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6cc64f17d074ff68cced49559981438",
      "value": 1
     }
    },
    "877d1854199e4362877dd8774f10bc23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_426e41f07cb145408a12146dff293ad6",
       "IPY_MODEL_865bc4814f3742cdb1d2230f141a8e72",
       "IPY_MODEL_2048f8794fef499cb0757fad16437a92"
      ],
      "layout": "IPY_MODEL_92b9d2b9889a4d92a3907c5791df3091"
     }
    },
    "92b9d2b9889a4d92a3907c5791df3091": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aafb2c69887549648e9c7044d6a344f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08e3f965a5ea4b338aba411dbb969ec6",
      "placeholder": "​",
      "style": "IPY_MODEL_b4943d26f11e46358a64ca534efade84",
      "value": "Running tokenizer on train dataset:  90%"
     }
    },
    "ac7711f32d374b74b6f7949db6d2cb94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4943d26f11e46358a64ca534efade84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edd1fc29c36a4beda3528a5b962d5d4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6cc64f17d074ff68cced49559981438": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
