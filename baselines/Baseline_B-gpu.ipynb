{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEkdLm_JF84s"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/afrisenti-semeval/afrisent-semeval-2023/main/afrisenti-logo.png\" width=\"30%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXY0zNpmLM1Z"
   },
   "source": [
    "<center>\n",
    "\n",
    "#SemEval 2023 Shared Task 12: AfriSenti (Task B)\n",
    "\n",
    "###Starter Notebook\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3wrnOfUBE7A"
   },
   "source": [
    "Baseline code based on the starter code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4BB4JDx5W8d"
   },
   "source": [
    "#1) Installations and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DObkW3ulM7yg"
   },
   "source": [
    "##a. Mount drive (if you are running on colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-OZxUWIMqtq"
   },
   "source": [
    "##b. Clone or update competition repository\n",
    "\n",
    "After cloning, under MyDrive, you will see afrisenti-semeval-2023 folder with all the the data for the afrisenti shared task (training and dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7543,
     "status": "ok",
     "timestamp": 1666885506158,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "2392TKadMvqT",
    "outputId": "03cb9124-7f93-48f8-a967-d65a19204470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\Downloads\\afrisent\n",
      "C:\\Users\\Thomas\\Downloads\\afrisent\\afrisent-semeval-2023\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\Thomas\\Downloads\\afrisent\n",
    "\n",
    "import os\n",
    "\n",
    "PROJECT_DIR = 'C:/Users/Thomas/Downloads/afrisent/afrisent-semeval-2023'\n",
    "PROJECT_GITHUB_URL = 'https://github.com/afrisenti-semeval/afrisent-semeval-2023.git'\n",
    "\n",
    "if not os.path.isdir(PROJECT_DIR):\n",
    "  !git clone {PROJECT_GITHUB_URL}\n",
    "else:\n",
    "  %cd {PROJECT_DIR}\n",
    "  pass\n",
    "#   !git pull {PROJECT_GITHUB_URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb03Gp9fUN8C"
   },
   "source": [
    "##c. Install required libraries\n",
    "\n",
    "- Set the project dire\n",
    "ctory in the cell below, where the requirements file should also be located, and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22962,
     "status": "ok",
     "timestamp": 1666885529114,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "4Cbmi_mQ4k3a",
    "outputId": "23f6e1ef-216a-4d88-b238-82c069142e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\Downloads\\afrisent\\afrisent-semeval-2023\n",
      "Requirement already satisfied: pandas in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 2)) (1.21.5)\n",
      "Requirement already satisfied: transformers in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 3)) (4.23.1)\n",
      "Requirement already satisfied: torch>=1.3 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 4)) (1.12.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 5)) (1.7.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 6)) (3.19.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: accelerate in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 8)) (0.13.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 9)) (0.1.97)\n",
      "Requirement already satisfied: datasets>=1.8.0 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 10)) (2.6.1)\n",
      "Requirement already satisfied: evaluate in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from -r starter_kit/requirements.txt (line 11)) (0.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from pandas->-r starter_kit/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from pandas->-r starter_kit/requirements.txt (line 1)) (2021.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from transformers->-r starter_kit/requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from transformers->-r starter_kit/requirements.txt (line 3)) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from transformers->-r starter_kit/requirements.txt (line 3)) (0.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from transformers->-r starter_kit/requirements.txt (line 3)) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from transformers->-r starter_kit/requirements.txt (line 3)) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from transformers->-r starter_kit/requirements.txt (line 3)) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from transformers->-r starter_kit/requirements.txt (line 3)) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from transformers->-r starter_kit/requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from torch>=1.3->-r starter_kit/requirements.txt (line 4)) (4.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from scikit-learn->-r starter_kit/requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from scikit-learn->-r starter_kit/requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from accelerate->-r starter_kit/requirements.txt (line 8)) (5.8.0)\n",
      "Requirement already satisfied: dill<0.3.6 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (0.70.13)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (2022.2.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (9.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers->-r starter_kit/requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->-r starter_kit/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from requests->transformers->-r starter_kit/requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from requests->transformers->-r starter_kit/requirements.txt (line 3)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from requests->transformers->-r starter_kit/requirements.txt (line 3)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from requests->transformers->-r starter_kit/requirements.txt (line 3)) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers->-r starter_kit/requirements.txt (line 3)) (0.4.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (1.6.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\thomas\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=1.8.0->-r starter_kit/requirements.txt (line 10)) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "%cd {PROJECT_DIR}\n",
    "\n",
    "if os.path.isdir(PROJECT_DIR):\n",
    "  #The requirements file should be in PROJECT_DIR\n",
    "  if os.path.isfile(os.path.join(PROJECT_DIR, 'starter_kit/requirements.txt')):\n",
    "    !pip install -r starter_kit/requirements.txt\n",
    "  else:\n",
    "    print('requirements.txt file not found')\n",
    "\n",
    "else:\n",
    "  print(\"Project directory not found, please check again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zszKhh2Ufb3"
   },
   "source": [
    "##d. Import libraries\n",
    "\n",
    "Import libraries below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1666885529649,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "8QIl420aUM1O"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Please don not edit anything here\n",
    "languages = ['am', 'dz', 'ha', 'ig', 'ma', 'pcm', 'pt', 'sw', 'yo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoRyMJMDJ7lF"
   },
   "source": [
    "#2) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wk5vMnrXMSS"
   },
   "source": [
    "##a. Formatting\n",
    "\n",
    "The training dataset that was provided for the competition is in the following format:\n",
    "\n",
    "| ID | text | label |\n",
    "| --- | --- | --- |\n",
    "| twt001 | example text | negative |\n",
    "| twt002 | example text | positive |\n",
    "| ... | ... | ... |\n",
    "\n",
    "However, the code in the starter kit do not expect the \n",
    "ID and require the training (and evaluation) data to be in the following format\n",
    "\n",
    "|text | label |\n",
    "|--- | --- |\n",
    "|example text | negative |\n",
    "|example text | positive |\n",
    "|... | ... |\n",
    "\n",
    "To reformat the data run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666885529650,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "QzoSbWC678Zm",
    "outputId": "f41a0d08-a8e2-4476-eff2-9f7042815865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found.\n"
     ]
    }
   ],
   "source": [
    "# Training Data Paths\n",
    "\n",
    "TASK = 'SubtaskB'\n",
    "TRAINING_DATA_DIR = os.path.join(PROJECT_DIR, TASK)\n",
    "FORMATTED_TRAIN_DATA = os.path.join(TRAINING_DATA_DIR, 'formatted-train-data')\n",
    "\n",
    "if os.path.isdir(TRAINING_DATA_DIR):\n",
    "  print('Data directory found.')\n",
    "  if not os.path.isdir(FORMATTED_TRAIN_DATA):\n",
    "    print('Creating directory to store formatted data.')\n",
    "    os.mkdir(FORMATTED_TRAIN_DATA)\n",
    "else:\n",
    "  print(TRAINING_DATA_DIR + ' is not a valid directory or does not exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1666885530810,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "ssyIZOUJMrzM",
    "outputId": "7017c9e1-618e-403b-bbd6-348c3a433f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\Downloads\\afrisent\\afrisent-semeval-2023\\SubtaskB\n",
      "formatted-train-data skipped!\n",
      "multilingual_dev.tsv skipped!\n",
      "README.txt skipped!\n",
      "splitted-train-dev-test skipped!\n"
     ]
    }
   ],
   "source": [
    "%cd {TRAINING_DATA_DIR}\n",
    "\n",
    "training_files = os.listdir()\n",
    "\n",
    "if len(training_files) > 0:\n",
    "  for training_file in training_files:\n",
    "    if training_file.endswith('train.tsv'):\n",
    "\n",
    "      data = training_file.split('_')[0]\n",
    "      if not os.path.isdir(os.path.join(FORMATTED_TRAIN_DATA, data)):\n",
    "        print(data, 'Creating directory to store train, dev and test splits.')\n",
    "        os.mkdir(os.path.join(FORMATTED_TRAIN_DATA, data))\n",
    "      \n",
    "      df = pd.read_csv(training_file, sep='\\t', names=['ID', 'text', 'label'], header=0)\n",
    "      df[['text', 'label']].to_csv(os.path.join(FORMATTED_TRAIN_DATA, data, 'train.tsv'), sep='\\t', index=False)\n",
    "    else:\n",
    "      print(training_file + ' skipped!')\n",
    "else:\n",
    "  print('No files are found in this directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S2Dup8GHl1Q"
   },
   "source": [
    "After running the code above, a new folder (called formated-train-data) with formated files is created in the \"datasets\" folder in the train sub-folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LgeVN_wXGrq"
   },
   "source": [
    "##b. <font color='red'>`(Optional) Creating Evaluation (Dev and Test) sets from the available training data`</font>\n",
    "\n",
    "You may wish to create train and evaluation (dev and test) sets from the training data provided. If you wish to do so, you can run any of the cells below`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APxVxL06lfux"
   },
   "source": [
    "###i. If you want to create both the Dev and Test sets, run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1666885531711,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "aVq1Blz0YF2b",
    "outputId": "c495ff82-b075-405a-bbf3-b65841658163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found.\n",
      "C:\\Users\\Thomas\\Downloads\\afrisent\\afrisent-semeval-2023\\SubtaskB\\formatted-train-data\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(FORMATTED_TRAIN_DATA):\n",
    "  print('Data directory found.')\n",
    "  SPLITTED_DATA = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev-test')\n",
    "  if not os.path.isdir(SPLITTED_DATA):\n",
    "    print('Creating directory to store train, dev and test splits.')\n",
    "    os.mkdir(SPLITTED_DATA)\n",
    "else:\n",
    "  print(FORMATTED_TRAIN_DATA + ' is not a valid directory or does not exist!')\n",
    "\n",
    "%cd {FORMATTED_TRAIN_DATA}\n",
    "formatted_training_files = os.listdir()\n",
    "\n",
    "if len(formatted_training_files) > 0:\n",
    "  for data_name in formatted_training_files:\n",
    "    formatted_training_file = os.path.join(data_name, 'train.tsv')\n",
    "    if os.path.isfile(formatted_training_file):\n",
    "      labeled_tweets = pd.read_csv(formatted_training_file, sep='\\t', names=['text', 'label'], header=0)\n",
    "      train, dev, test = np.split(labeled_tweets.sample(frac=1, random_state=42), [int(.7*len(labeled_tweets)), int(.8*len(labeled_tweets))])\n",
    "\n",
    "      if not os.path.isdir(os.path.join(SPLITTED_DATA, data_name)):\n",
    "        print(data_name, 'Creating directory to store train, dev and test splits.')\n",
    "        os.mkdir(os.path.join(SPLITTED_DATA, data_name))\n",
    "\n",
    "      train.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name, 'train.tsv'), sep='\\t', index=False)\n",
    "      dev.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name, 'dev.tsv'), sep='\\t', index=False)\n",
    "      test.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name,'test.tsv'), sep='\\t', index=False)\n",
    "    else:\n",
    "      print(training_file + ' is not a supported file!')\n",
    "else:\n",
    "  print('No files are found in this directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZy_rzouJZFz"
   },
   "source": [
    "After running the code above, a new folder (called splitted-train-dev-test) with train-dev-test split is created in the \"datasets\" folder in the train sub-folder. Here, the train-dev-test split is 70/10/20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4UObc2ql-Zd"
   },
   "source": [
    "###ii. If you want to create only the Dev set from the training data, please run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666885531711,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "tU24jW_gmFu9"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# if os.path.isdir(FORMATTED_TRAIN_DATA):\n",
    "#   print('Data directory found.')\n",
    "#   SPLITTED_DATA = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev')\n",
    "#   if not os.path.isdir(SPLITTED_DATA):\n",
    "#     print('Creating directory to store train, dev and test splits.')\n",
    "#     os.mkdir(SPLITTED_DATA)\n",
    "# else:\n",
    "#   print(FORMATTED_TRAIN_DATA + ' is not a valid directory or does not exist!')\n",
    "\n",
    "# %cd {FORMATTED_TRAIN_DATA}\n",
    "# formatted_training_files = os.listdir()\n",
    "\n",
    "# if len(formatted_training_files) > 0:\n",
    "#   for data_name in formatted_training_files:\n",
    "#     formatted_training_file = os.path.join(data_name, 'train.tsv')\n",
    "#     if os.path.isfile(formatted_training_file):\n",
    "#       labeled_tweets = pd.read_csv(formatted_training_file, sep='\\t', names=['text', 'label'], header=0)\n",
    "#       train, dev = train_test_split(labeled_tweets, test_size=0.3)\n",
    "\n",
    "#       if not os.path.isdir(os.path.join(SPLITTED_DATA, data_name)):\n",
    "#         print(data_name, 'Creating directory to store train, dev and test splits.')\n",
    "#         os.mkdir(os.path.join(SPLITTED_DATA, data_name))\n",
    "\n",
    "#       train.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name, 'train.tsv'), sep='\\t', index=False)\n",
    "#       dev.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name, 'dev.tsv'), sep='\\t', index=False)\n",
    "#     else:\n",
    "#       print(training_file + ' is not a supported file!')\n",
    "# else:\n",
    "#   print('No files are found in this directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usfr00QhKSnd"
   },
   "source": [
    "After running the code above, a new folder (called splitted-train-dev) with train-dev split is created in the \"datasets\" folder in the train sub-folder. Here, the train-dev split is 70/30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoyRlje3Rm7"
   },
   "source": [
    "#3) Training setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AaXec415s0f"
   },
   "source": [
    "##a. Set project parameters\n",
    "\n",
    "For a list of models that be used for fine-tuning, you can check [HERE](https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666885531712,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "M0TKIFrE5ybV",
    "outputId": "d842a10d-7ba4-4c32-9829-8120b38884bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\Downloads\\afrisent\\afrisent-semeval-2023\n",
      "Everything set. You can now start model training.\n"
     ]
    }
   ],
   "source": [
    "%cd {PROJECT_DIR}\n",
    "\n",
    "# Model Training Parameters\n",
    "MODEL_NAME_OR_PATH = 'Davlan/afro-xlmr-mini'\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-5\n",
    "NUMBER_OF_TRAINING_EPOCHS = 5\n",
    "MAXIMUM_SEQUENCE_LENGTH = 128\n",
    "SAVE_STEPS = -1\n",
    "\n",
    "print('Everything set. You can now start model training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2qcCQnU8dgQ"
   },
   "source": [
    "##b. Train the model\n",
    "\n",
    "In the section below, we provide three options: \n",
    "\n",
    "- 1) training model without any validation; \n",
    "- 2) training model with validation but without testing; \n",
    "- 3) training a model with validation and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fEw-qcEhYnx"
   },
   "source": [
    "###Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sE22Nmnx9lf1"
   },
   "source": [
    "\n",
    "\n",
    "####Starter Code: Datasets, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45621,
     "status": "ok",
     "timestamp": 1666885577329,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "ERP2sja3i3uQ",
    "outputId": "26decac5-a979-4758-a428-82fc8602886c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22acca7a470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import warnings\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "from datasets import Features, Value, ClassLabel, load_dataset, Dataset\n",
    "\n",
    "require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/text-classification/requirements.txt\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "np.random.seed(420)\n",
    "torch.manual_seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1666885577331,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "2k6XKSygMnT4",
    "outputId": "1335f4d4-fd01-4a4b-bee0-9c3cec91529a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Thomas/Downloads/afrisent/afrisent-semeval-2023\\\\SubtaskB'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1666885689007,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "EJPw829sIRY3"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev-test', 'multilingual')\n",
    "EVAL_DIR = os.path.join(PROJECT_DIR, TASK, 'dev')\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'models', 'multilingual')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUMBER_OF_TRAINING_EPOCHS,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    overwrite_output_dir=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1666885691402,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "60upFv0znHN5"
   },
   "outputs": [],
   "source": [
    "data_args = SimpleNamespace(**{\n",
    "    'max_seq_length': MAXIMUM_SEQUENCE_LENGTH,\n",
    "    'overwrite_cache': False,\n",
    "    'pad_to_max_length': True,\n",
    "    'max_train_samples': None,\n",
    "    'max_eval_samples': None,\n",
    "    'max_predict_samples': None\n",
    "})\n",
    "\n",
    "model_args = SimpleNamespace(**{\n",
    "    'model_name_or_path': MODEL_NAME_OR_PATH,\n",
    "    'config_name': None,\n",
    "    'tokenizer_name': None,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'eval_dir': EVAL_DIR,\n",
    "    'cache_dir': None,\n",
    "    'do_lower_case': None,\n",
    "    'use_fast_tokenizer': True,\n",
    "    'model_revision': 'main',\n",
    "    'use_auth_token': False,\n",
    "    'ignore_mismatched_sizes': False\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666885692512,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "2Nx63rcbnHXy"
   },
   "outputs": [],
   "source": [
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "# parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "# model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "# Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n",
    "# information sent is the one passed as arguments along with your Python/PyTorch versions.\n",
    "#send_example_telemetry(\"run_xnli\", model_args)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "log_level = 0 #training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1666885693653,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "yGlFrGztnhVX",
    "outputId": "b43f902f-6cf1-4308-cb86-ca881c4763df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/30/2022 08:55:35 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "# Detecting last checkpoint.\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None:\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1666885695345,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "hZc-mzkXnhdF",
    "outputId": "c0bf16c2-9acc-4a85-a092-629ce1b6e6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral', 'negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "# Set seed before initializing model.\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "# In distributed training, the load_dataset function guarantees that only one local process can concurrently\n",
    "# download the dataset.\n",
    "# Downloading and loading xnli dataset from the hub.\n",
    "\n",
    "\n",
    "if training_args.do_train:\n",
    "\n",
    "    #train_dataset = load_dataset('csv', data_files={'train': model_args.data_dir + '/train.csv'}, cache_dir=model_args.cache_dir)\n",
    "    #df = train_dataset[\"train\"].to_pandas()\n",
    "    #label_list = df['label'].unique().tolist()\n",
    "    #label_list = train_dataset.features[\"label\"].names\n",
    "    df = pd.read_csv(model_args.data_dir + '/train.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    train_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "if training_args.do_eval:\n",
    "    #eval_dataset = load_dataset('csv', data_files={'validation': model_args.data_dir + '/dev.csv'}, cache_dir=model_args.cache_dir)\n",
    "\n",
    "    #df = eval_dataset[\"validation\"].to_pandas()\n",
    "    #label_list = df['label'].unique().tolist()\n",
    "    #label_list = eval_dataset.features[\"label\"].names\n",
    "    df = pd.read_csv(model_args.data_dir + '/dev.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    eval_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "if training_args.do_predict:\n",
    "    #predict_dataset = load_dataset('csv', data_files={'test': model_args.data_dir + '/test.csv'}, cache_dir=model_args.cache_dir)\n",
    "\n",
    "    #df = predict_dataset[\"test\"].to_pandas()\n",
    "    #label_list = df['label'].unique().tolist()\n",
    "    #label_list = predict_dataset.features[\"label\"].names\n",
    "    df = pd.read_csv(model_args.data_dir + '/test.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    predict_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "# Labels\n",
    "num_labels = len(label_list)\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9gxi4Ll-HFQ"
   },
   "source": [
    "####Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314,
     "referenced_widgets": [
      "29ac9c39fcc34bb2b6f4e7acd0a874ac",
      "279f524ecc8540ada3c3da6d12e5396b",
      "caa44b22427a44e8b5579abb04d761f6",
      "9cfcb0ad7c3e4fef8e94c6eaab10aff6",
      "6894eb4c50494b06a38ad16d68f9efd1",
      "603800b4b3fd4b5196e285b485fc84f6",
      "1c534293d5484fd0a5836c0893d820fe",
      "7b4a72d6390f4a7ab06c7b45c4f4d7f1",
      "e4360bc1a54745fa86300a0419ed2ec1",
      "c0be402727b7432c953381c4b42d5475",
      "82d71ccba0b044c4bac1393f7c1432f8",
      "23942d2eb5cd470eb5cbb86559a903cc",
      "4b767f84d99245b68f710b144a1d53f4",
      "aa27f4e0a27f489386b0c7951308c977",
      "7a710b8de38540ecbc4d9003bc9c3325",
      "af17d23d71174299b769b0fd4c01d43c",
      "e223a3afe677477082e7222a91282372",
      "d5173ee4a65d473babe8f8a6faf30932",
      "002ce67e671242f6a36d3d3da312bee3",
      "c35086bdc2d14b03ada6adcf168dc670",
      "d376c5305d0144a485258d379b3df96b",
      "3d6175126f384cc0a310fffc17433712",
      "2639ba7461a1472db505b12d6a4ce460",
      "63479de032b2407893f05985b8823285",
      "4e2840117e04409ca325a0fb266bdceb",
      "fb403e8f46cb4dbabd12c9f92d5dc345",
      "52eacb5678d44ca292d243f08502b9d1",
      "c8618191ad144f73aa3a8e31be66db00",
      "507f7f4e9fd8432cb59fcb651568be89",
      "d14aac539b7c4609b27ad6b839f30463",
      "1e71e63b92b64477a20df94a8d82d958",
      "090092831b364c72a08504b67ff2ba26",
      "4564a607daed4988998671913b4454fe",
      "7aab5f8bcd954c2eb1dde765ae6cc0b8",
      "8ada663b7eae42baaf6e7e2ad9480207",
      "cd5c0a2dce764ee6adfcd384b2d23f03",
      "066d508ded5242159591a79edcb2df44",
      "141c3c017ecf4aa69b8b63c5305f98c0",
      "223a773fddbe494fb5ed332d26db1eda",
      "acf3100f434949cf97e9f2baabce935c",
      "5af9506d1eaf40a6a902151d94a3ff34",
      "c02b8e5ced1242b0b47b897d25a87d08",
      "0d62cfe0fd524937aa7a74229a12860d",
      "becf38076bbf486eaf6a553743909e82",
      "fe453473f6bf4b1294e858bdd164e6b4",
      "493cd55595e848f7aa06e2c96ce512b6",
      "4107da8a1822493b9101c8100a7692d8",
      "1c0d4c21ddc54cdabc8e124ea1679a50",
      "70f12982917341dc9519763d426df387",
      "89bcf27ece3043758c19e377487ce491",
      "c50c779549ec44d6b0631d3b74957a47",
      "cf160cb0befb4b67984dd44da1290bd3",
      "18bb14d1faff47388aa0a3f331b866b2",
      "d8b7cf17dec34da1a773721a919bc261",
      "c27370b4b3ba4d34a87c7a5bcbf20fb5",
      "37df0d1225754a3c80aac20061cda526",
      "a7846652776b435187b375361753c716",
      "568be2abd445475cb0c2b864bdc46429",
      "3ced9e99d69643a7b2d7839ea3b69407",
      "fdd85c7288064b97a1f59b9d39a484b1",
      "8ce81588460e45cea369f7ec231663a7",
      "5eb2062b7a2e4f7a97d531464919b9f8",
      "99d36ac004024e73a5b58246bd954d78",
      "9f6a5f42300843c79272f299fa798df1",
      "146af9828c544609b692a53fd82e559e",
      "1a664fea4bd04c66a8f6a6b2747795b9"
     ]
    },
    "executionInfo": {
     "elapsed": 23255,
     "status": "ok",
     "timestamp": 1666885720135,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "pd_l2PG3nhiY",
    "outputId": "d9516e74-c113-4a1d-e1cd-8f77e08be77a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:2596] 2022-10-30 08:55:37,473 >> Some weights of the model checkpoint at Davlan/afro-xlmr-mini were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:2608] 2022-10-30 08:55:37,477 >> Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-mini and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "# In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab.\n",
    "#         finetuning_task=\"xnli\",\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    do_lower_case=model_args.do_lower_case,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    use_fast=model_args.use_fast_tokenizer,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    "    ignore_mismatched_sizes=model_args.ignore_mismatched_sizes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666885720136,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "slMaLbYvnHmP",
    "outputId": "1e41002d-ff5c-4209-a866-eb35a6ed391f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def preprocess_function(examples):\\n    # Tokenize the texts\\n    return tokenizer(\\n        examples[\"premise\"],\\n        examples[\"hypothesis\"],\\n        padding=padding,\\n        max_length=data_args.max_seq_length,\\n        truncation=True,\\n    )\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the datasets\n",
    "# Padding strategy\n",
    "if data_args.pad_to_max_length:\n",
    "    padding = \"max_length\"\n",
    "else:\n",
    "    # We will pad later, dynamically at batch creation, to the max sequence length in each batch\n",
    "    padding = False\n",
    "\n",
    "# Some models have set the order of the labels to use, so let's make sure we do use it.\n",
    "label_to_id = None\n",
    "label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "\n",
    "if label_to_id is not None:\n",
    "    model.config.label2id = label_to_id\n",
    "    model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "\n",
    "'''\n",
    "    def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    return tokenizer(\n",
    "        examples[\"premise\"],\n",
    "        examples[\"hypothesis\"],\n",
    "        padding=padding,\n",
    "        max_length=data_args.max_seq_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "988e32ece0cd43d699e4f4a093126386",
      "c46a83ac3f084b31bf6ae2e44203338f",
      "fd17a8170dfe49ca84cd52e0da18a3e3",
      "1abe5791a7484abab12e2f4142382f18",
      "4203bdff116a45b6976c3e9d3bd15d0b",
      "c1efa718727b429d9c5e2c45a770d177",
      "77715b89cbd144e782f2bf26e1637d99",
      "a48eac32073647d5b51cf5d1c5dfcd6b",
      "1fecacd3920e4e48ab087d52c4202217",
      "44a1e833e69240d4bb4f5cbe62f8851f",
      "bd8e4e3d092d4b25a447d62428b5fd67",
      "1f6e23a7575e43df806cc73814b8e38b",
      "b473e000a6854761be9932ac14650ba8",
      "91a5ec0fa5f346efbf514f8c56e23bf5",
      "8a1ab42b3ecd4205baa04fd23a25d09f",
      "f7389d7f0c244eef93212fb17cc3e4ee",
      "aac1b214c70047d0aaeaa420577c8e83",
      "d450757d0bb44933ae26149366689493",
      "d18d2ce3957c4e1c812d765cf515bb03",
      "8c68c891aeb14324a18ab62e2777129f",
      "5d2a2adb068848be9d4995a2420133ce",
      "ce70a3671a4544efaa9ed7d5d13b8612"
     ]
    },
    "executionInfo": {
     "elapsed": 123585,
     "status": "ok",
     "timestamp": 1666885843714,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "gKAQ2leboGN3",
    "outputId": "4f93b634-a812-4b52-d7b7-37b4d90b5572"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c87dcb238842b79b9f955deb5818da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset:   0%|          | 0/40 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f7eff1736f4ed3af54319597cd7de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    #print\n",
    "    texts =(examples['text'],)\n",
    "    result = tokenizer(*texts, padding=padding, max_length=data_args.max_seq_length, truncation=True)\n",
    "    #print(examples['text'])\n",
    "    #result = tokenizer(examples['text'], examples['text'], padding=padding, max_length=data_args.max_seq_length, truncation=True)\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    \n",
    "    result['length'], result[\"tokenized\"] = [], []\n",
    "    for input_ids in result['input_ids']:\n",
    "        toks = tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=True)\n",
    "        result['length'].append(len(toks)+2)\n",
    "        result['tokenized'].append(' '.join(toks))\n",
    "    return result\n",
    "\n",
    "if training_args.do_train:\n",
    "    if data_args.max_train_samples is not None:\n",
    "        max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
    "        train_dataset = train_dataset.select(range(max_train_samples))\n",
    "    with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "        train_dataset = train_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on train dataset\",\n",
    "        )\n",
    "    # Log a few random samples from the training set:\n",
    "    for index in random.sample(range(len(train_dataset)), 3):\n",
    "        logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "\n",
    "if training_args.do_eval:\n",
    "    if data_args.max_eval_samples is not None:\n",
    "        max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
    "        eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
    "    with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "        eval_dataset = eval_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on validation dataset\",\n",
    "        )\n",
    "\n",
    "if training_args.do_predict:\n",
    "    if data_args.max_predict_samples is not None:\n",
    "        max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n",
    "        predict_dataset = predict_dataset.select(range(max_predict_samples))\n",
    "    with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n",
    "        predict_dataset = predict_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on prediction dataset\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666885843716,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "6Hi6VwK5O1ve",
    "outputId": "ed19f4f4-5604-4821-f55e-4511879c5e08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'attention_mask', 'length', 'tokenized'],\n",
       "     num_rows: 39268\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'attention_mask', 'length', 'tokenized'],\n",
       "     num_rows: 5610\n",
       " }))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1666885843953,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "6EnnkjSTKk4-"
   },
   "outputs": [],
   "source": [
    "train_text, train_labels = train_dataset['tokenized'], train_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666885843953,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "tNt_9ZMsKnr8"
   },
   "outputs": [],
   "source": [
    "eval_text, eval_labels = eval_dataset['tokenized'], eval_dataset['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lEqGqVv-TgQ"
   },
   "source": [
    "#### Simple Baselines\n",
    "\n",
    "Class Proportions (AKA Constant / Majority Classifier Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666885843954,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "pIsze7tckrbK",
    "outputId": "28c26a14-edb6-45bc-9f01-e7b01a42dbbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37344028520499106\n",
      "0.3092691622103387\n",
      "0.3172905525846702\n"
     ]
    }
   ],
   "source": [
    "for l in np.unique(eval_labels):\n",
    "  print(np.mean(np.array(eval_labels) == l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 21040,
     "status": "ok",
     "timestamp": 1666885864990,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "2cmGwea_KtrM"
   },
   "outputs": [],
   "source": [
    "# # set up unigram, bigram, trigram BOW and TF-IDF\n",
    "\n",
    "# unigram_vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=100000, min_df=7, max_df=0.8)\n",
    "# unigram_vectorizer.fit(train_text)\n",
    "# X_train_unigram = unigram_vectorizer.transform(train_text)\n",
    "# X_test_unigram = unigram_vectorizer.transform(eval_text)\n",
    "\n",
    "# unigram_tf_idf_transformer = TfidfTransformer()\n",
    "# unigram_tf_idf_transformer.fit(X_train_unigram)\n",
    "# X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)\n",
    "# X_test_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_test_unigram)\n",
    "\n",
    "# bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=100000, min_df=7, max_df=0.8)\n",
    "# bigram_vectorizer.fit(train_text)\n",
    "# X_train_bigram = bigram_vectorizer.transform(train_text)\n",
    "# X_test_bigram = bigram_vectorizer.transform(eval_text)\n",
    "\n",
    "# bigram_tf_idf_transformer = TfidfTransformer()\n",
    "# bigram_tf_idf_transformer.fit(X_train_bigram)\n",
    "# X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)\n",
    "# X_test_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_test_bigram)\n",
    "\n",
    "# trigram_vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=100000, min_df=7, max_df=0.8)\n",
    "# trigram_vectorizer.fit(train_text)\n",
    "# X_train_trigram = trigram_vectorizer.transform(train_text)\n",
    "# X_test_trigram = trigram_vectorizer.transform(eval_text)\n",
    "# trigram_tf_idf_transformer = TfidfTransformer()\n",
    "# trigram_tf_idf_transformer.fit(X_train_trigram)\n",
    "# X_train_trigram_tf_idf =trigram_tf_idf_transformer.transform(X_train_trigram)\n",
    "# X_test_trigram_tf_idf =trigram_tf_idf_transformer.transform(X_test_trigram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666885864991,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "RArsspQ1HelL"
   },
   "outputs": [],
   "source": [
    "# def AdaDTC():\n",
    "#     return AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "\n",
    "# classifiers = [\n",
    "# #     (MultinomialNB, {\n",
    "# #         'alpha': [1e-6, 1e-3, 0.1, 1, 10, 1e3, 1e6]\n",
    "# #     }), \n",
    "# #     (SVC, {   \n",
    "# #         'C': [1e-6, 1e-3, 0.1, 1, 10, 1e3, 1e6],\n",
    "# #         'gamma':['scale', 'auto'],\n",
    "# #         'kernel': ['linear', 'poly', 'rbf'],\n",
    "# #         'max_iter': [1000]\n",
    "# #         }), \n",
    "# #     (LogisticRegression, {\n",
    "# #         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "# #         'C': [1e-6, 1e-3, 0.1, 1, 10, 1e3, 1e6],\n",
    "# #         'max_iter': [1000]\n",
    "# #     }), \n",
    "# #     (RandomForestClassifier, {\n",
    "# #         'n_estimators': [50, 100, 200, 500],\n",
    "# #         'criterion': ['gini', 'entropy'],\n",
    "# #         'max_depth': [3, 5, 10, None]\n",
    "# #     }), \n",
    "# #     (AdaDTC, {\n",
    "# #         \"base_estimator__criterion\" : [ \"entropy\"],\n",
    "# #         \"base_estimator__splitter\" :   [\"random\"],\n",
    "# #         \"base_estimator__max_depth\" :   [1, 3, 10],\n",
    "# #         \"learning_rate\": [ 1e-3, 0.1, 1, 10, 1e3],\n",
    "# #         \"n_estimators\": [50, 100, 200]\n",
    "# #         }), \n",
    "#     (MLPClassifier, {\n",
    "#         'activation': ['relu'],\n",
    "#         'alpha': [1e-6, 1e-3, 0.1],\n",
    "#         'learning_rate': ['constant', 'adaptive'],\n",
    "#         'hidden_layer_sizes': [(100,), (100, 100)]\n",
    "#     })\n",
    "#     ]\n",
    "\n",
    "# X_train_data = {'unigram counts': X_train_unigram,\n",
    "#                 'unigram tf-idf': X_train_unigram_tf_idf,\n",
    "#                 'bigram counts': X_train_bigram, \n",
    "#                 'bigram tf-idf': X_train_bigram_tf_idf,\n",
    "#                 'trigram counts': X_train_trigram, \n",
    "#                 'trigram tf-idf': X_train_trigram_tf_idf}\n",
    "\n",
    "# X_test_data = {'unigram counts': X_test_unigram,\n",
    "#                 'unigram tf-idf': X_test_unigram_tf_idf,\n",
    "#                 'bigram counts': X_test_bigram, \n",
    "#                 'bigram tf-idf': X_test_bigram_tf_idf,\n",
    "#                 'trigram counts': X_test_trigram, \n",
    "#                 'trigram tf-idf': X_test_trigram_tf_idf}\n",
    "\n",
    "# def train_and_show_scores(title, model, parameters):\n",
    "\n",
    "#     X_train, X_test = X_train_data[title], X_test_data[title]\n",
    "#     y_train, y_test = train_labels, eval_labels\n",
    "\n",
    "#     clf = GridSearchCV(model(), parameters)\n",
    "    \n",
    "#     with warnings.catch_warnings(record=True) as w:\n",
    "#         warnings.simplefilter(\"always\")\n",
    "#         clf.fit(X_train, y_train)\n",
    "#     train_score = clf.score(X_train, y_train)\n",
    "#     test_score = clf.score(X_test, y_test)\n",
    "#     print(f\"\"\"\n",
    "#     {title}\n",
    "#     Train score: {train_score:.3}\n",
    "#     Eval score: {test_score:.3}\n",
    "#     Params: {clf.best_params_}\n",
    "#     \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 21505,
     "status": "error",
     "timestamp": 1666885886491,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "6vktvdutUZm9",
    "outputId": "3ef61136-8b97-4c18-ebd7-502b337649f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Get scores for multiple different models\n",
    "# for model, parameters in classifiers:\n",
    "#     print(model)\n",
    "#     train_and_show_scores('unigram counts', model, parameters)\n",
    "#     train_and_show_scores('unigram tf-idf', model, parameters)\n",
    "#     train_and_show_scores('bigram counts', model, parameters)\n",
    "#     train_and_show_scores('bigram tf-idf', model, parameters)\n",
    "#     train_and_show_scores('trigram counts', model, parameters)\n",
    "#     train_and_show_scores('trigram tf-idf', model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"<class 'sklearn.naive_bayes.MultinomialNB'>\n",
    "\n",
    "    unigram counts\n",
    "    Train score: 0.625\n",
    "    Eval score: 0.576\n",
    "    Params: {'alpha': 0.1}\n",
    "    \n",
    "\n",
    "    unigram tf-idf\n",
    "    Train score: 0.653\n",
    "    Eval score: 0.604\n",
    "    Params: {'alpha': 1}\n",
    "    \n",
    "\n",
    "    bigram counts\n",
    "    Train score: 0.681\n",
    "    Eval score: 0.616\n",
    "    Params: {'alpha': 0.1}\n",
    "    \n",
    "\n",
    "    bigram tf-idf\n",
    "    Train score: 0.722\n",
    "    Eval score: 0.642\n",
    "    Params: {'alpha': 0.1}\n",
    "    \n",
    "\n",
    "    trigram counts\n",
    "    Train score: 0.683\n",
    "    Eval score: 0.616\n",
    "    Params: {'alpha': 0.1}\n",
    "    \n",
    "\n",
    "    trigram tf-idf\n",
    "    Train score: 0.702\n",
    "    Eval score: 0.639\n",
    "    Params: {'alpha': 1}\n",
    "    \n",
    "<class 'sklearn.svm._classes.SVC'>\n",
    "\n",
    "    unigram counts\n",
    "    Train score: 0.476\n",
    "    Eval score: 0.424\n",
    "    Params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
    "    \n",
    "\n",
    "    unigram tf-idf\n",
    "    Train score: 0.512\n",
    "    Eval score: 0.5\n",
    "    Params: {'C': 1000.0, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 1000}\n",
    "    \n",
    "\n",
    "    bigram counts\n",
    "    Train score: 0.441\n",
    "    Eval score: 0.431\n",
    "    Params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 1000}\n",
    "    \n",
    "\n",
    "    bigram tf-idf\n",
    "    Train score: 0.582\n",
    "    Eval score: 0.524\n",
    "    Params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
    "    \n",
    "\n",
    "    trigram counts\n",
    "    Train score: 0.476\n",
    "    Eval score: 0.452\n",
    "    Params: {'C': 1000000.0, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 1000}\n",
    "    \n",
    "\n",
    "    trigram tf-idf\n",
    "    Train score: 0.546\n",
    "    Eval score: 0.502\n",
    "    Params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
    "    \n",
    "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
    "\n",
    "    unigram counts\n",
    "    Train score: 0.742\n",
    "    Eval score: 0.633\n",
    "    Params: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "    \n",
    "\n",
    "    unigram tf-idf\n",
    "    Train score: 0.747\n",
    "    Eval score: 0.642\n",
    "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "    \n",
    "\n",
    "    bigram counts\n",
    "    Train score: 0.819\n",
    "    Eval score: 0.668\n",
    "    Params: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "    \n",
    "\n",
    "    bigram tf-idf\n",
    "    Train score: 0.807\n",
    "    Eval score: 0.675\n",
    "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "    \n",
    "\n",
    "    trigram counts\n",
    "    Train score: 0.825\n",
    "    Eval score: 0.668\n",
    "    Params: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "    \n",
    "\n",
    "    trigram tf-idf\n",
    "    Train score: 0.811\n",
    "    Eval score: 0.672\n",
    "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "    \n",
    "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
    "\n",
    "    unigram counts\n",
    "    Train score: 0.998\n",
    "    Eval score: 0.658\n",
    "    Params: {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 500}\n",
    "    \n",
    "\n",
    "    unigram tf-idf\n",
    "    Train score: 0.998\n",
    "    Eval score: 0.647\n",
    "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
    "    \n",
    "\n",
    "    bigram counts\n",
    "    Train score: 0.998\n",
    "    Eval score: 0.666\n",
    "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
    "    \n",
    "\n",
    "    bigram tf-idf\n",
    "    Train score: 0.998\n",
    "    Eval score: 0.651\n",
    "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
    "    \n",
    "\n",
    "    trigram counts\n",
    "    Train score: 0.998\n",
    "    Eval score: 0.662\n",
    "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
    "    \n",
    "\n",
    "    trigram tf-idf\n",
    "    Train score: 0.998\n",
    "    Eval score: 0.652\n",
    "    Params: {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 500}\n",
    "    \n",
    "<function AdaDTC at 0x000001AE8A5150D0>\n",
    "\n",
    "    unigram counts\n",
    "    Train score: 0.665\n",
    "    Eval score: 0.615\n",
    "    Params: {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
    "    \n",
    "\n",
    "    unigram tf-idf\n",
    "    Train score: 0.67\n",
    "    Eval score: 0.614\n",
    "    Params: {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
    "    \n",
    "\n",
    "    bigram counts\n",
    "    Train score: 0.677\n",
    "    Eval score: 0.635\n",
    "    Params: {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
    "    \n",
    "\n",
    "    bigram tf-idf\n",
    "    Train score: 0.678\n",
    "    Eval score: 0.623\n",
    "    Params: {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
    "    \n",
    "\n",
    "    trigram counts\n",
    "    Train score: 0.68\n",
    "    Eval score: 0.636\n",
    "    Params: {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
    "    \n",
    "\n",
    "    trigram tf-idf\n",
    "    Train score: 0.678\n",
    "    Eval score: 0.625\n",
    "    Params: {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
    "    \"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1666885886492,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "piucart2uCIl"
   },
   "outputs": [],
   "source": [
    "# # Clear Memory\n",
    "# del unigram_vectorizer\n",
    "# del X_train_unigram \n",
    "# del X_test_unigram\n",
    "\n",
    "# del unigram_tf_idf_transformer\n",
    "# del X_train_unigram_tf_idf\n",
    "# del X_test_unigram_tf_idf\n",
    "                                                             \n",
    "# del bigram_vectorizer\n",
    "# del X_train_bigram\n",
    "# del X_test_bigram\n",
    "\n",
    "# del bigram_tf_idf_transformer\n",
    "# del X_train_bigram_tf_idf\n",
    "# del X_test_bigram_tf_idf\n",
    "\n",
    "# del trigram_vectorizer\n",
    "# del X_train_trigram\n",
    "# del X_test_trigram\n",
    "\n",
    "# del trigram_tf_idf_transformer\n",
    "# del X_train_trigram_tf_idf\n",
    "# del X_test_trigram_tf_idf\n",
    "\n",
    "# del X_train_data\n",
    "# del X_test_data \n",
    "\n",
    "# del train_text\n",
    "# del eval_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNWVct2XARap"
   },
   "source": [
    "####LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1666885577517,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "U6a2g_l1rZan"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1666885577518,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "6tSt7NFOezKe"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, emb_dim=300, num_layers=1, dropout=0.5, lstm_dropout=0.0):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(len(tokenizer), emb_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size=emb_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True,\n",
    "                            dropout=lstm_dropout)\n",
    "        \n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.fc = nn.Linear(2*hidden_dim, 3)\n",
    "\n",
    "    def forward(self, text, text_len):\n",
    "\n",
    "        text_emb = self.embedding(text)\n",
    "\n",
    "        packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        out_forward = output[range(len(output)), text_len - 1, :self.hidden_dim]\n",
    "        out_reverse = output[:, 0, self.hidden_dim:]\n",
    "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
    "        text_fea = self.drop(out_reduced)\n",
    "\n",
    "        text_fea = self.fc(text_fea)\n",
    "        text_fea = torch.squeeze(text_fea, 1)\n",
    "        text_out = text_fea\n",
    "        return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1666885577518,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "KzLIu8Jo7QJq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7853, 31415, 5610)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pts = len(train_dataset)\n",
    "shuffled_ids = np.arange(num_pts, dtype=int)\n",
    "np.random.shuffle(shuffled_ids)\n",
    "\n",
    "valid_ids = torch.LongTensor(np.array(train_dataset['input_ids'])[shuffled_ids[:num_pts // 5]])\n",
    "valid_lengths = torch.LongTensor(np.array(train_dataset['length'])[shuffled_ids[:num_pts // 5]]).cpu()\n",
    "valid_labels = torch.LongTensor(np.array(train_dataset['label'])[shuffled_ids[:num_pts // 5]])\n",
    "\n",
    "train_ids = torch.LongTensor(np.array(train_dataset['input_ids'])[shuffled_ids[num_pts // 5:]])\n",
    "train_lengths = torch.LongTensor(np.array(train_dataset['length'])[shuffled_ids[num_pts // 5:]]).cpu()\n",
    "train_labels = torch.LongTensor(np.array(train_dataset['label'])[shuffled_ids[num_pts // 5:]])\n",
    "\n",
    "eval_ids = torch.LongTensor(eval_dataset['input_ids'])\n",
    "eval_lengths = torch.LongTensor(eval_dataset['length']).cpu()\n",
    "eval_labels = torch.LongTensor(eval_dataset['label'])\n",
    "len(valid_ids), len(train_ids), len(eval_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1666885577518,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "n_ZIAx_8UZzA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 0.0287 Val Acc: 0.601, Eval Acc: N/A, Eval Acc @ Best Val 0.609, Eval F1: 0.621: 100%|| 982/98\n",
      "Epoch 2/15, Train Loss: 0.0223 Val Acc: 0.635, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/982\n",
      "Epoch 3/15, Train Loss: 0.0157 Val Acc: 0.639, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/982\n",
      "Epoch 4/15, Train Loss: 0.00995 Val Acc: 0.635, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/98\n",
      "Epoch 5/15, Train Loss: 0.00604 Val Acc: 0.633, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/98\n",
      "Epoch 6/15, Train Loss: 0.00396 Val Acc: 0.631, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/98\n",
      "Epoch 7/15, Train Loss: 0.00298 Val Acc: 0.636, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/98\n",
      "Epoch 8/15, Train Loss: 0.00236 Val Acc: 0.637, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/98\n",
      "Epoch 9/15, Train Loss: 0.00175 Val Acc: 0.636, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/98\n",
      "Epoch 10/15, Train Loss: 0.00157 Val Acc: 0.627, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/9\n",
      "Epoch 11/15, Train Loss: 0.00141 Val Acc: 0.635, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/9\n",
      "Epoch 12/15, Train Loss: 0.00123 Val Acc: 0.643, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/9\n",
      "Epoch 13/15, Train Loss: 0.00107 Val Acc: 0.641, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/9\n",
      "Epoch 14/15, Train Loss: 0.000997 Val Acc: 0.636, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/\n",
      "Epoch 15/15, Train Loss: 0.000901 Val Acc: 0.639, Eval Acc: N/A, Eval Acc @ Best Val 0.647, Eval F1: 0.65: 100%|| 982/\n"
     ]
    }
   ],
   "source": [
    "def train(criterion = nn.CrossEntropyLoss(),\n",
    "          batch_size = 32,\n",
    "          num_epochs = 30,\n",
    "          eval_every = 4,\n",
    "          params={},\n",
    "          lr=0.0005,\n",
    "          leave=False):\n",
    "    model = LSTM(**params).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    eval_every = (len(train_ids) / batch_size) // eval_every\n",
    "    best_valid_acc = 0\n",
    "    best_valid_f1 = 0\n",
    "    model.train()\n",
    "    best_preds = []\n",
    "    for epoch in range(num_epochs):\n",
    "        pbar = tqdm(range(0, len(train_ids), batch_size), leave=leave, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        total_train_loss = 0.0\n",
    "        total_points = 0\n",
    "        for i in pbar:           \n",
    "            labels = train_labels[i:i+batch_size].to(device)\n",
    "            inps = train_ids[i:i+batch_size].to(device)\n",
    "            lengths = train_lengths[i:i+batch_size]#.to(device)\n",
    "            output = model(inps, lengths)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            total_train_loss += loss.item()\n",
    "            total_points += labels.size(0)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + batch_size) % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    num_correct = 0\n",
    "                    eval_batch_size = 100\n",
    "                    for j in range(0, len(valid_ids), eval_batch_size):\n",
    "                        labels = valid_labels[j:j+eval_batch_size].to(device)\n",
    "                        inps = valid_ids[j:j+eval_batch_size].to(device)\n",
    "                        lengths = valid_lengths[j:j+eval_batch_size]#.to(device)\n",
    "                        output = model(inps, lengths)\n",
    "                        output = torch.argmax(output, -1)\n",
    "                        num_correct += torch.sum(output == labels).cpu().numpy()\n",
    "                    valid_accuracy = num_correct / len(valid_ids)\n",
    "\n",
    "                    accuracy = \"N/A\"\n",
    "                    preds = np.array([])\n",
    "                    if valid_accuracy > best_valid_acc:\n",
    "                        num_correct = 0\n",
    "                        eval_batch_size = 100\n",
    "                        for j in range(0, len(eval_ids), eval_batch_size):\n",
    "                            labels = eval_labels[j:j+eval_batch_size].to(device)\n",
    "                            inps = eval_ids[j:j+eval_batch_size].to(device)\n",
    "                            lengths = eval_lengths[j:j+eval_batch_size]#.to(device)\n",
    "                            output = model(inps, lengths)\n",
    "                            output = torch.argmax(output, -1)\n",
    "                            preds = np.append(preds, output.cpu().numpy())\n",
    "                            num_correct += torch.sum(output == labels).cpu().numpy()\n",
    "                        accuracy = num_correct / len(eval_ids)\n",
    "                        best_valid_f1 = f1_score(preds, eval_labels, average='weighted')\n",
    "                        best_preds = preds\n",
    "                        best_valid_acc = accuracy\n",
    "                    pbar.set_description(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {(total_train_loss / total_points):.3} ' + \\\n",
    "                                         f'Val Acc: {valid_accuracy:.3}, Eval Acc: {accuracy:.3}, Eval Acc @ Best Val {best_valid_acc:.3}, Eval F1: {best_valid_f1:.3}')\n",
    "                model.train()\n",
    "    return best_valid_acc, best_valid_f1, best_preds, eval_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acc, f1, preds, labels = train(num_epochs=15, params={\n",
    "    'hidden_dim': 128, 'emb_dim': 300, 'num_layers': 2, 'dropout': 0.0, 'lstm_dropout': 0.5},\n",
    "      lr=0.001, leave=True)\n",
    "pd.DataFrame([[acc, f1, str(list(preds)), str(list(labels))]], columns=['acc', 'f1', 'preds', 'labels']).to_csv('combined_lstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1666885577520,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "-uWlHsFwUZ8z"
   },
   "outputs": [],
   "source": [
    "del train_ids\n",
    "del train_lengths\n",
    "del train_labels\n",
    "\n",
    "del eval_ids\n",
    "del eval_lengths\n",
    "del eval_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZx_-UywAcmj"
   },
   "source": [
    "####Pretrained Transformer Baseline - xlmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 115796,
     "status": "aborted",
     "timestamp": 1666885577520,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "7xpriZKGrFCK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:06:08,336 >> The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Thomas\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1607] 2022-10-30 09:06:08,349 >> ***** Running training *****\n",
      "[INFO|trainer.py:1608] 2022-10-30 09:06:08,349 >>   Num examples = 39268\n",
      "[INFO|trainer.py:1609] 2022-10-30 09:06:08,350 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1610] 2022-10-30 09:06:08,350 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:1611] 2022-10-30 09:06:08,350 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1612] 2022-10-30 09:06:08,351 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1613] 2022-10-30 09:06:08,351 >>   Total optimization steps = 6140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6140' max='6140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6140/6140 15:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.998300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.883900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.804200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.760500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.517400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.516200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:1852] 2022-10-30 09:21:51,370 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2656] 2022-10-30 09:21:51,386 >> Saving model checkpoint to C:/Users/Thomas/Downloads/afrisent/afrisent-semeval-2023\\models\\multilingual\n",
      "[INFO|configuration_utils.py:447] 2022-10-30 09:21:51,386 >> Configuration saved in C:/Users/Thomas/Downloads/afrisent/afrisent-semeval-2023\\models\\multilingual\\config.json\n",
      "[INFO|modeling_utils.py:1624] 2022-10-30 09:21:52,127 >> Model weights saved in C:/Users/Thomas/Downloads/afrisent/afrisent-semeval-2023\\models\\multilingual\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2123] 2022-10-30 09:21:52,127 >> tokenizer config file saved in C:/Users/Thomas/Downloads/afrisent/afrisent-semeval-2023\\models\\multilingual\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2130] 2022-10-30 09:21:52,127 >> Special tokens file saved in C:/Users/Thomas/Downloads/afrisent/afrisent-semeval-2023\\models\\multilingual\\special_tokens_map.json\n",
      "[INFO|trainer.py:725] 2022-10-30 09:21:52,419 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:21:52,419 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:21:52,419 >>   Num examples = 5610\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:21:52,419 >>   Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  total_flos               =  3011357GF\n",
      "  train_loss               =     0.6834\n",
      "  train_runtime            = 0:15:43.03\n",
      "  train_samples            =      39268\n",
      "  train_samples_per_second =      208.2\n",
      "  train_steps_per_second   =      6.511\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:02,212 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:02,214 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:02,214 >>   Num examples = 5610\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:02,214 >>   Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6937370735472712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96696db923846d28420cac28ded10b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:14,112 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:14,114 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:14,114 >>   Num examples = 599\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:14,114 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b7f902d98d415bb111be3e1940cdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:15,598 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:15,602 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:15,603 >>   Num examples = 165\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:15,603 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a32d3002934f12b8577f1ff16985aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:18,923 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:18,928 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:18,928 >>   Num examples = 1417\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:18,928 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9288d9891a4414bcb8e18f638e34ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:23,954 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:23,956 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:23,956 >>   Num examples = 1019\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:23,956 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe9124d017d4267aee0ea815df1cfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:27,162 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:27,163 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:27,164 >>   Num examples = 558\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:27,164 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f02d0d4162e489f9d8d4b14c1cf303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:29,306 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:29,307 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:29,308 >>   Num examples = 512\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:29,308 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf24b6a46b6f48e0b468cd362be6cb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:31,040 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:31,042 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:31,043 >>   Num examples = 306\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:31,044 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e20c4bcabf74d5686f0007ee24647ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:32,036 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:32,037 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:32,038 >>   Num examples = 181\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:32,038 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cd6ea6d03b408c9fe2a164e9a35eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:22:34,465 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:22:34,467 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:22:34,467 >>   Num examples = 852\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:22:34,467 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.7641\n",
      "  eval_loss               =     0.5471\n",
      "  eval_runtime            = 0:00:01.68\n",
      "  eval_samples_per_second =    505.729\n",
      "  eval_steps_per_second   =     63.513\n"
     ]
    }
   ],
   "source": [
    "# Get the metric function\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "# predictions and label_ids field) and has to return a dictionary string to float.\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "if data_args.pad_to_max_length:\n",
    "    data_collator = default_data_collator\n",
    "elif training_args.fp16:\n",
    "    data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n",
    "else:\n",
    "    data_collator = None\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    elif last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    metrics = train_result.metrics\n",
    "    max_train_samples = (\n",
    "        data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "    )\n",
    "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "# Evaluation\n",
    "if training_args.do_eval or True:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "    max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "    metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "    \n",
    "    \n",
    "    splitted_A = os.path.join(PROJECT_DIR, 'SubtaskA', 'train', 'splitted-train-dev-test')\n",
    "    \n",
    "    try:\n",
    "        LANGUAGE_CODE\n",
    "    except NameError:\n",
    "        LANGUAGE_CODE = 'combined'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    predictions, labels, metrics = trainer.predict(eval_dataset, metric_key_prefix=\"predict\")\n",
    "    print(f1_score(np.argmax(predictions, axis=-1), labels, average='weighted'))\n",
    "\n",
    "    for lang in languages:\n",
    "        eval_path = os.path.join(splitted_A, lang)\n",
    "        df = pd.read_csv(eval_path + '/dev.tsv', sep='\\t')\n",
    "        df = df.dropna()\n",
    "        lang_eval = Dataset.from_pandas(df)\n",
    "        lang_eval = lang_eval.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on validation dataset\",\n",
    "        )\n",
    "        \n",
    "        predictions, labels, metrics = trainer.predict(lang_eval, metric_key_prefix=\"eval\")\n",
    "        \n",
    "        data.append([LANGUAGE_CODE, lang, str(list(predictions)), str(list(labels))])\n",
    "    df = pd.DataFrame(data, columns=['source', 'target', 'predictions', 'labels'])\n",
    "    df.to_csv(f'{LANGUAGE_CODE}_preds.csv', index=False)\n",
    "\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "# Prediction\n",
    "if training_args.do_predict:\n",
    "    logger.info(\"*** Predict ***\")\n",
    "    predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n",
    "\n",
    "    max_predict_samples = (\n",
    "        data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\n",
    "    )\n",
    "    metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"predict\", metrics)\n",
    "    trainer.save_metrics(\"predict\", metrics)\n",
    "\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    output_predict_file = os.path.join(training_args.output_dir, \"predictions.txt\")\n",
    "    if trainer.is_world_process_zero():\n",
    "        with open(output_predict_file, \"w\") as writer:\n",
    "            writer.write(\"index\\tprediction\\n\")\n",
    "            for index, item in enumerate(predictions):\n",
    "                item = label_list[item]\n",
    "                writer.write(f\"{index}\\t{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:725] 2022-10-30 09:24:46,131 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: length, text, tokenized. If length, text, tokenized are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2907] 2022-10-30 09:24:46,133 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2909] 2022-10-30 09:24:46,133 >>   Num examples = 5610\n",
      "[INFO|trainer.py:2912] 2022-10-30 09:24:46,133 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(eval_dataset, metric_key_prefix=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43meval_dataset\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eval_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6934046345811051"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(predictions, axis=-1) == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6937370735472712\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(np.argmax(predictions, axis=-1), labels, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h06uE1yLGAG_"
   },
   "source": [
    "#### KinyaBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 115789,
     "status": "aborted",
     "timestamp": 1666885577521,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "1EGi2jpx5BvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "kinya = 'jean-paul/KinyaBERT-small'\n",
    "\n",
    "DATA_DIR = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev-test', 'multilingual')\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'models', 'multilingual')\n",
    "\n",
    "!python starter_kit/run_textclass.py \\\n",
    "  --model_name_or_path {kinya} \\\n",
    "  --data_dir {DATA_DIR} \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --do_predict \\\n",
    "  --per_device_train_batch_size {BATCH_SIZE} \\\n",
    "  --learning_rate {MAXIMUM_SEQUENCE_LENGTH} \\\n",
    "  --num_train_epochs {NUMBER_OF_TRAINING_EPOCHS} \\\n",
    "  --max_seq_length {MAXIMUM_SEQUENCE_LENGTH} \\\n",
    "  --output_dir {OUTPUT_DIR} \\\n",
    "  --save_steps {SAVE_STEPS} \\\n",
    "  --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d203a7fbe37afbb990fedfc21c321928443618f3d7b991e0237ff71906aa031f"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "002ce67e671242f6a36d3d3da312bee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "066d508ded5242159591a79edcb2df44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d62cfe0fd524937aa7a74229a12860d",
      "placeholder": "",
      "style": "IPY_MODEL_becf38076bbf486eaf6a553743909e82",
      "value": " 9.08M/9.08M [00:00&lt;00:00, 19.7MB/s]"
     }
    },
    "090092831b364c72a08504b67ff2ba26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d62cfe0fd524937aa7a74229a12860d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "141c3c017ecf4aa69b8b63c5305f98c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "146af9828c544609b692a53fd82e559e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18bb14d1faff47388aa0a3f331b866b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a664fea4bd04c66a8f6a6b2747795b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1abe5791a7484abab12e2f4142382f18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44a1e833e69240d4bb4f5cbe62f8851f",
      "placeholder": "",
      "style": "IPY_MODEL_bd8e4e3d092d4b25a447d62428b5fd67",
      "value": " 39/40 [01:42&lt;00:04,  4.13s/ba]"
     }
    },
    "1c0d4c21ddc54cdabc8e124ea1679a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8b7cf17dec34da1a773721a919bc261",
      "placeholder": "",
      "style": "IPY_MODEL_c27370b4b3ba4d34a87c7a5bcbf20fb5",
      "value": " 239/239 [00:00&lt;00:00, 4.85kB/s]"
     }
    },
    "1c534293d5484fd0a5836c0893d820fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e71e63b92b64477a20df94a8d82d958": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f6e23a7575e43df806cc73814b8e38b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b473e000a6854761be9932ac14650ba8",
       "IPY_MODEL_91a5ec0fa5f346efbf514f8c56e23bf5",
       "IPY_MODEL_8a1ab42b3ecd4205baa04fd23a25d09f"
      ],
      "layout": "IPY_MODEL_f7389d7f0c244eef93212fb17cc3e4ee"
     }
    },
    "1fecacd3920e4e48ab087d52c4202217": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "223a773fddbe494fb5ed332d26db1eda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23942d2eb5cd470eb5cbb86559a903cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b767f84d99245b68f710b144a1d53f4",
       "IPY_MODEL_aa27f4e0a27f489386b0c7951308c977",
       "IPY_MODEL_7a710b8de38540ecbc4d9003bc9c3325"
      ],
      "layout": "IPY_MODEL_af17d23d71174299b769b0fd4c01d43c"
     }
    },
    "2639ba7461a1472db505b12d6a4ce460": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63479de032b2407893f05985b8823285",
       "IPY_MODEL_4e2840117e04409ca325a0fb266bdceb",
       "IPY_MODEL_fb403e8f46cb4dbabd12c9f92d5dc345"
      ],
      "layout": "IPY_MODEL_52eacb5678d44ca292d243f08502b9d1"
     }
    },
    "279f524ecc8540ada3c3da6d12e5396b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_603800b4b3fd4b5196e285b485fc84f6",
      "placeholder": "",
      "style": "IPY_MODEL_1c534293d5484fd0a5836c0893d820fe",
      "value": "Downloading: 100%"
     }
    },
    "29ac9c39fcc34bb2b6f4e7acd0a874ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_279f524ecc8540ada3c3da6d12e5396b",
       "IPY_MODEL_caa44b22427a44e8b5579abb04d761f6",
       "IPY_MODEL_9cfcb0ad7c3e4fef8e94c6eaab10aff6"
      ],
      "layout": "IPY_MODEL_6894eb4c50494b06a38ad16d68f9efd1"
     }
    },
    "37df0d1225754a3c80aac20061cda526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7846652776b435187b375361753c716",
       "IPY_MODEL_568be2abd445475cb0c2b864bdc46429",
       "IPY_MODEL_3ced9e99d69643a7b2d7839ea3b69407"
      ],
      "layout": "IPY_MODEL_fdd85c7288064b97a1f59b9d39a484b1"
     }
    },
    "3ced9e99d69643a7b2d7839ea3b69407": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_146af9828c544609b692a53fd82e559e",
      "placeholder": "",
      "style": "IPY_MODEL_1a664fea4bd04c66a8f6a6b2747795b9",
      "value": " 472M/472M [00:12&lt;00:00, 34.1MB/s]"
     }
    },
    "3d6175126f384cc0a310fffc17433712": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4107da8a1822493b9101c8100a7692d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf160cb0befb4b67984dd44da1290bd3",
      "max": 239,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18bb14d1faff47388aa0a3f331b866b2",
      "value": 239
     }
    },
    "4203bdff116a45b6976c3e9d3bd15d0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a1e833e69240d4bb4f5cbe62f8851f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4564a607daed4988998671913b4454fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "493cd55595e848f7aa06e2c96ce512b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89bcf27ece3043758c19e377487ce491",
      "placeholder": "",
      "style": "IPY_MODEL_c50c779549ec44d6b0631d3b74957a47",
      "value": "Downloading: 100%"
     }
    },
    "4b767f84d99245b68f710b144a1d53f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e223a3afe677477082e7222a91282372",
      "placeholder": "",
      "style": "IPY_MODEL_d5173ee4a65d473babe8f8a6faf30932",
      "value": "Downloading: 100%"
     }
    },
    "4e2840117e04409ca325a0fb266bdceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d14aac539b7c4609b27ad6b839f30463",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e71e63b92b64477a20df94a8d82d958",
      "value": 5069051
     }
    },
    "507f7f4e9fd8432cb59fcb651568be89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52eacb5678d44ca292d243f08502b9d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "568be2abd445475cb0c2b864bdc46429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99d36ac004024e73a5b58246bd954d78",
      "max": 471656786,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f6a5f42300843c79272f299fa798df1",
      "value": 471656786
     }
    },
    "5af9506d1eaf40a6a902151d94a3ff34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d2a2adb068848be9d4995a2420133ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eb2062b7a2e4f7a97d531464919b9f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "603800b4b3fd4b5196e285b485fc84f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63479de032b2407893f05985b8823285": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8618191ad144f73aa3a8e31be66db00",
      "placeholder": "",
      "style": "IPY_MODEL_507f7f4e9fd8432cb59fcb651568be89",
      "value": "Downloading: 100%"
     }
    },
    "6894eb4c50494b06a38ad16d68f9efd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70f12982917341dc9519763d426df387": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77715b89cbd144e782f2bf26e1637d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a710b8de38540ecbc4d9003bc9c3325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d376c5305d0144a485258d379b3df96b",
      "placeholder": "",
      "style": "IPY_MODEL_3d6175126f384cc0a310fffc17433712",
      "value": " 435/435 [00:00&lt;00:00, 9.73kB/s]"
     }
    },
    "7aab5f8bcd954c2eb1dde765ae6cc0b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ada663b7eae42baaf6e7e2ad9480207",
       "IPY_MODEL_cd5c0a2dce764ee6adfcd384b2d23f03",
       "IPY_MODEL_066d508ded5242159591a79edcb2df44"
      ],
      "layout": "IPY_MODEL_141c3c017ecf4aa69b8b63c5305f98c0"
     }
    },
    "7b4a72d6390f4a7ab06c7b45c4f4d7f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82d71ccba0b044c4bac1393f7c1432f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89bcf27ece3043758c19e377487ce491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a1ab42b3ecd4205baa04fd23a25d09f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d2a2adb068848be9d4995a2420133ce",
      "placeholder": "",
      "style": "IPY_MODEL_ce70a3671a4544efaa9ed7d5d13b8612",
      "value": " 5/6 [00:20&lt;00:03,  3.02s/ba]"
     }
    },
    "8ada663b7eae42baaf6e7e2ad9480207": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_223a773fddbe494fb5ed332d26db1eda",
      "placeholder": "",
      "style": "IPY_MODEL_acf3100f434949cf97e9f2baabce935c",
      "value": "Downloading: 100%"
     }
    },
    "8c68c891aeb14324a18ab62e2777129f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ce81588460e45cea369f7ec231663a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91a5ec0fa5f346efbf514f8c56e23bf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d18d2ce3957c4e1c812d765cf515bb03",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8c68c891aeb14324a18ab62e2777129f",
      "value": 5
     }
    },
    "988e32ece0cd43d699e4f4a093126386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c46a83ac3f084b31bf6ae2e44203338f",
       "IPY_MODEL_fd17a8170dfe49ca84cd52e0da18a3e3",
       "IPY_MODEL_1abe5791a7484abab12e2f4142382f18"
      ],
      "layout": "IPY_MODEL_4203bdff116a45b6976c3e9d3bd15d0b"
     }
    },
    "99d36ac004024e73a5b58246bd954d78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cfcb0ad7c3e4fef8e94c6eaab10aff6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0be402727b7432c953381c4b42d5475",
      "placeholder": "",
      "style": "IPY_MODEL_82d71ccba0b044c4bac1393f7c1432f8",
      "value": " 721/721 [00:00&lt;00:00, 15.1kB/s]"
     }
    },
    "9f6a5f42300843c79272f299fa798df1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a48eac32073647d5b51cf5d1c5dfcd6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7846652776b435187b375361753c716": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ce81588460e45cea369f7ec231663a7",
      "placeholder": "",
      "style": "IPY_MODEL_5eb2062b7a2e4f7a97d531464919b9f8",
      "value": "Downloading: 100%"
     }
    },
    "aa27f4e0a27f489386b0c7951308c977": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_002ce67e671242f6a36d3d3da312bee3",
      "max": 435,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c35086bdc2d14b03ada6adcf168dc670",
      "value": 435
     }
    },
    "aac1b214c70047d0aaeaa420577c8e83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acf3100f434949cf97e9f2baabce935c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af17d23d71174299b769b0fd4c01d43c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b473e000a6854761be9932ac14650ba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aac1b214c70047d0aaeaa420577c8e83",
      "placeholder": "",
      "style": "IPY_MODEL_d450757d0bb44933ae26149366689493",
      "value": "Running tokenizer on validation dataset:  83%"
     }
    },
    "bd8e4e3d092d4b25a447d62428b5fd67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "becf38076bbf486eaf6a553743909e82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c02b8e5ced1242b0b47b897d25a87d08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0be402727b7432c953381c4b42d5475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1efa718727b429d9c5e2c45a770d177": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c27370b4b3ba4d34a87c7a5bcbf20fb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c35086bdc2d14b03ada6adcf168dc670": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c46a83ac3f084b31bf6ae2e44203338f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1efa718727b429d9c5e2c45a770d177",
      "placeholder": "",
      "style": "IPY_MODEL_77715b89cbd144e782f2bf26e1637d99",
      "value": "Running tokenizer on train dataset:  98%"
     }
    },
    "c50c779549ec44d6b0631d3b74957a47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8618191ad144f73aa3a8e31be66db00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caa44b22427a44e8b5579abb04d761f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b4a72d6390f4a7ab06c7b45c4f4d7f1",
      "max": 721,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4360bc1a54745fa86300a0419ed2ec1",
      "value": 721
     }
    },
    "cd5c0a2dce764ee6adfcd384b2d23f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5af9506d1eaf40a6a902151d94a3ff34",
      "max": 9081351,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c02b8e5ced1242b0b47b897d25a87d08",
      "value": 9081351
     }
    },
    "ce70a3671a4544efaa9ed7d5d13b8612": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf160cb0befb4b67984dd44da1290bd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d14aac539b7c4609b27ad6b839f30463": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d18d2ce3957c4e1c812d765cf515bb03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d376c5305d0144a485258d379b3df96b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d450757d0bb44933ae26149366689493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5173ee4a65d473babe8f8a6faf30932": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8b7cf17dec34da1a773721a919bc261": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e223a3afe677477082e7222a91282372": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4360bc1a54745fa86300a0419ed2ec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f7389d7f0c244eef93212fb17cc3e4ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb403e8f46cb4dbabd12c9f92d5dc345": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_090092831b364c72a08504b67ff2ba26",
      "placeholder": "",
      "style": "IPY_MODEL_4564a607daed4988998671913b4454fe",
      "value": " 5.07M/5.07M [00:00&lt;00:00, 27.2MB/s]"
     }
    },
    "fd17a8170dfe49ca84cd52e0da18a3e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a48eac32073647d5b51cf5d1c5dfcd6b",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fecacd3920e4e48ab087d52c4202217",
      "value": 39
     }
    },
    "fdd85c7288064b97a1f59b9d39a484b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe453473f6bf4b1294e858bdd164e6b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_493cd55595e848f7aa06e2c96ce512b6",
       "IPY_MODEL_4107da8a1822493b9101c8100a7692d8",
       "IPY_MODEL_1c0d4c21ddc54cdabc8e124ea1679a50"
      ],
      "layout": "IPY_MODEL_70f12982917341dc9519763d426df387"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
