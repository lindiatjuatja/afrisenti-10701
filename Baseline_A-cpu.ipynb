{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEkdLm_JF84s"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/afrisenti-semeval/afrisent-semeval-2023/main/afrisenti-logo.png\" width=\"30%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXY0zNpmLM1Z"
   },
   "source": [
    "<center>\n",
    "\n",
    "#SemEval 2023 Shared Task 12: AfriSenti (Task A)\n",
    "\n",
    "###Starter Notebook\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3wrnOfUBE7A"
   },
   "source": [
    "Baseline code based on the starter code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4BB4JDx5W8d"
   },
   "source": [
    "#1) Installations and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DObkW3ulM7yg"
   },
   "source": [
    "##a. Mount drive (if you are running on colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-OZxUWIMqtq"
   },
   "source": [
    "##b. Clone or update competition repository\n",
    "\n",
    "After cloning, under MyDrive, you will see afrisenti-semeval-2023 folder with all the the data for the afrisenti shared task (training and dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17192,
     "status": "ok",
     "timestamp": 1666932930576,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "OsuZvweV6jzo",
    "outputId": "601e0364-95f3-4c0e-d3e9-fa63688e3546"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Language to train sentiment classifier for\n",
    "# am dz ha ig ma pcm pt sw yo\n",
    "\n",
    "LANGUAGE_CODE = 'yo'\n",
    "folder = ''\n",
    "\n",
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    proj_folder = '/content/drive/MyDrive'\n",
    "else:\n",
    "    proj_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6974,
     "status": "ok",
     "timestamp": 1666932941234,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "2392TKadMvqT",
    "outputId": "a5427066-2d8f-4e1f-ccda-46eddb636031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thomas/afrisent\n",
      "/Users/thomas/afrisent/afrisent-semeval-2023\n",
      "From https://github.com/afrisenti-semeval/afrisent-semeval-2023\n",
      " * branch            HEAD       -> FETCH_HEAD\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "%cd {proj_folder}\n",
    "\n",
    "\n",
    "PROJECT_DIR = f'{proj_folder}/afrisent-semeval-2023'\n",
    "PROJECT_GITHUB_URL = 'https://github.com/afrisenti-semeval/afrisent-semeval-2023.git'\n",
    "\n",
    "if not os.path.isdir(PROJECT_DIR):\n",
    "  !git clone {PROJECT_GITHUB_URL}\n",
    "else:\n",
    "  %cd {PROJECT_DIR}\n",
    "  !git pull {PROJECT_GITHUB_URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb03Gp9fUN8C"
   },
   "source": [
    "##c. Install required libraries\n",
    "\n",
    "- Set the project dire\n",
    "ctory in the cell below, where the requirements file should also be located, and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Cbmi_mQ4k3a"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%cd {PROJECT_DIR}\n",
    "\n",
    "if os.path.isdir(PROJECT_DIR):\n",
    "  #The requirements file should be in PROJECT_DIR\n",
    "  if os.path.isfile(os.path.join(PROJECT_DIR, 'starter_kit/requirements.txt')):\n",
    "    !pip install -r starter_kit/requirements.txt\n",
    "  else:\n",
    "    print('requirements.txt file not found')\n",
    "\n",
    "else:\n",
    "  print(\"Project directory not found, please check again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zszKhh2Ufb3"
   },
   "source": [
    "##d. Import libraries\n",
    "\n",
    "Import libraries below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8QIl420aUM1O"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Please don not edit anything here\n",
    "languages = ['am', 'dz', 'ha', 'ig', 'ma', 'pcm', 'pt', 'sw', 'yo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoRyMJMDJ7lF"
   },
   "source": [
    "#2) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wk5vMnrXMSS"
   },
   "source": [
    "##a. Formatting\n",
    "\n",
    "The training dataset that was provided for the competition is in the following format:\n",
    "\n",
    "| ID | text | label |\n",
    "| --- | --- | --- |\n",
    "| twt001 | example text | negative |\n",
    "| twt002 | example text | positive |\n",
    "| ... | ... | ... |\n",
    "\n",
    "However, the code in the starter kit do not expect the \n",
    "ID and require the training (and evaluation) data to be in the following format\n",
    "\n",
    "|text | label |\n",
    "|--- | --- |\n",
    "|example text | negative |\n",
    "|example text | positive |\n",
    "|... | ... |\n",
    "\n",
    "To reformat the data run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666884271530,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "QzoSbWC678Zm",
    "outputId": "69eacc7f-cad8-4bad-9f0f-71c4c32758ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found.\n"
     ]
    }
   ],
   "source": [
    "# Training Data Paths\n",
    "\n",
    "TASK = 'SubtaskA'\n",
    "TRAINING_DATA_DIR = os.path.join(PROJECT_DIR, TASK, 'train')\n",
    "FORMATTED_TRAIN_DATA = os.path.join(TRAINING_DATA_DIR, 'formatted-train-data')\n",
    "\n",
    "if os.path.isdir(TRAINING_DATA_DIR):\n",
    "  print('Data directory found.')\n",
    "  if not os.path.isdir(FORMATTED_TRAIN_DATA):\n",
    "    print('Creating directory to store formatted data.')\n",
    "    os.mkdir(FORMATTED_TRAIN_DATA)\n",
    "else:\n",
    "  print(TRAINING_DATA_DIR + ' is not a valid directory or does not exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1666884272475,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "ssyIZOUJMrzM",
    "outputId": "7a883beb-a7cd-44ca-8ab8-84147f25295d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thomas/afrisent/afrisent-semeval-2023/SubtaskA/train\n",
      "splitted-train-dev-test skipped!\n",
      "formatted-train-data skipped!\n",
      "README.txt skipped!\n"
     ]
    }
   ],
   "source": [
    "%cd {TRAINING_DATA_DIR}\n",
    "\n",
    "training_files = os.listdir()\n",
    "\n",
    "if len(training_files) > 0:\n",
    "  for training_file in training_files:\n",
    "    if training_file.endswith('.tsv'):\n",
    "\n",
    "      data = training_file.split('_')[0]\n",
    "      if not os.path.isdir(os.path.join(FORMATTED_TRAIN_DATA, data)):\n",
    "        print(data, 'Creating directory to store train, dev and test splits.')\n",
    "        os.mkdir(os.path.join(FORMATTED_TRAIN_DATA, data))\n",
    "      \n",
    "      df = pd.read_csv(training_file, sep='\\t', names=['ID', 'text', 'label'], header=0)\n",
    "      df[['text', 'label']].to_csv(os.path.join(FORMATTED_TRAIN_DATA, data, 'train.tsv'), sep='\\t', index=False)\n",
    "    else:\n",
    "      print(training_file + ' skipped!')\n",
    "else:\n",
    "  print('No files are found in this directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S2Dup8GHl1Q"
   },
   "source": [
    "After running the code above, a new folder (called formated-train-data) with formated files is created in the \"datasets\" folder in the train sub-folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LgeVN_wXGrq"
   },
   "source": [
    "##b. <font color='red'>`(Optional) Creating Evaluation (Dev and Test) sets from the available training data`</font>\n",
    "\n",
    "You may wish to create train and evaluation (dev and test) sets from the training data provided. If you wish to do so, you can run any of the cells below`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APxVxL06lfux"
   },
   "source": [
    "###i. If you want to create both the Dev and Test sets, run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1371,
     "status": "ok",
     "timestamp": 1666884273844,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "aVq1Blz0YF2b",
    "outputId": "f1397651-bded-49cb-e9ff-e9eac2dfe952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found.\n",
      "/Users/thomas/afrisent/afrisent-semeval-2023/SubtaskA/train/formatted-train-data\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(FORMATTED_TRAIN_DATA):\n",
    "  print('Data directory found.')\n",
    "  SPLITTED_DATA = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev-test')\n",
    "  if not os.path.isdir(SPLITTED_DATA):\n",
    "    print('Creating directory to store train, dev and test splits.')\n",
    "    os.mkdir(SPLITTED_DATA)\n",
    "else:\n",
    "  print(FORMATTED_TRAIN_DATA + ' is not a valid directory or does not exist!')\n",
    "\n",
    "%cd {FORMATTED_TRAIN_DATA}\n",
    "formatted_training_files = os.listdir()\n",
    "\n",
    "if len(formatted_training_files) > 0:\n",
    "  for data_name in formatted_training_files:\n",
    "    formatted_training_file = os.path.join(data_name, 'train.tsv')\n",
    "    if os.path.isfile(formatted_training_file):\n",
    "      labeled_tweets = pd.read_csv(formatted_training_file, sep='\\t', names=['text', 'label'], header=0)\n",
    "      train, dev, test = np.split(labeled_tweets.sample(frac=1, random_state=42), [int(.7*len(labeled_tweets)), int(.8*len(labeled_tweets))])\n",
    "\n",
    "      if not os.path.isdir(os.path.join(SPLITTED_DATA, data_name)):\n",
    "        print(data_name, 'Creating directory to store train, dev and test splits.')\n",
    "        os.mkdir(os.path.join(SPLITTED_DATA, data_name))\n",
    "\n",
    "      train.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name, 'train.tsv'), sep='\\t', index=False)\n",
    "      dev.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name, 'dev.tsv'), sep='\\t', index=False)\n",
    "      test.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name,'test.tsv'), sep='\\t', index=False)\n",
    "    else:\n",
    "      print(training_file + ' is not a supported file!')\n",
    "else:\n",
    "  print('No files are found in this directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZy_rzouJZFz"
   },
   "source": [
    "After running the code above, a new folder (called splitted-train-dev-test) with train-dev-test split is created in the \"datasets\" folder in the train sub-folder. Here, the train-dev-test split is 70/10/20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4UObc2ql-Zd"
   },
   "source": [
    "###ii. If you want to create only the Dev set from the training data, please run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tU24jW_gmFu9"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# if os.path.isdir(FORMATTED_TRAIN_DATA):\n",
    "#   print('Data directory found.')\n",
    "#   SPLITTED_DATA = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev')\n",
    "#   if not os.path.isdir(SPLITTED_DATA):\n",
    "#     print('Creating directory to store train, dev and test splits.')\n",
    "#     os.mkdir(SPLITTED_DATA)\n",
    "# else:\n",
    "#   print(FORMATTED_TRAIN_DATA + ' is not a valid directory or does not exist!')\n",
    "\n",
    "# %cd {FORMATTED_TRAIN_DATA}\n",
    "# formatted_training_files = os.listdir()\n",
    "\n",
    "# if len(formatted_training_files) > 0:\n",
    "#   for data_name in formatted_training_files:\n",
    "#     formatted_training_file = os.path.join(data_name, 'train.tsv')\n",
    "#     if os.path.isfile(formatted_training_file):\n",
    "#       labeled_tweets = pd.read_csv(formatted_training_file, sep='\\t', names=['text', 'label'], header=0)\n",
    "#       train, dev = train_test_split(labeled_tweets, test_size=0.3)\n",
    "\n",
    "#       if not os.path.isdir(os.path.join(SPLITTED_DATA, data_name)):\n",
    "#         print(data_name, 'Creating directory to store train, dev and test splits.')\n",
    "#         os.mkdir(os.path.join(SPLITTED_DATA, data_name))\n",
    "\n",
    "#       train.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name, 'train.tsv'), sep='\\t', index=False)\n",
    "#       dev.sample(frac=1).to_csv(os.path.join(SPLITTED_DATA, data_name, 'dev.tsv'), sep='\\t', index=False)\n",
    "#     else:\n",
    "#       print(training_file + ' is not a supported file!')\n",
    "# else:\n",
    "#   print('No files are found in this directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usfr00QhKSnd"
   },
   "source": [
    "After running the code above, a new folder (called splitted-train-dev) with train-dev split is created in the \"datasets\" folder in the train sub-folder. Here, the train-dev split is 70/30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoyRlje3Rm7"
   },
   "source": [
    "#3) Training setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AaXec415s0f"
   },
   "source": [
    "##a. Set project parameters\n",
    "\n",
    "For a list of models that be used for fine-tuning, you can check [HERE](https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666884274396,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "M0TKIFrE5ybV",
    "outputId": "d0b5ee8b-20f7-4fa3-b8b6-65b773c70060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thomas/afrisent/afrisent-semeval-2023\n",
      "Everything set. You can now start model training.\n"
     ]
    }
   ],
   "source": [
    "%cd {PROJECT_DIR}\n",
    "\n",
    "if LANGUAGE_CODE in languages:\n",
    "  # Model Training Parameters\n",
    "  MODEL_NAME_OR_PATH = 'Davlan/afro-xlmr-mini'\n",
    "  BATCH_SIZE = 32\n",
    "  LEARNING_RATE = 5e-5\n",
    "  NUMBER_OF_TRAINING_EPOCHS = 5\n",
    "  MAXIMUM_SEQUENCE_LENGTH = 128\n",
    "  SAVE_STEPS = -1\n",
    "\n",
    "  print('Everything set. You can now start model training.')\n",
    "\n",
    "else:\n",
    "  print(\"Invalid language code/Dataset not released. Please input any of the following released data\\n\\n\\t- 'am'\\n\\t- 'dz'\\n\\t- 'ha'\\n\\t- 'ig'\\n\\t- 'ma'\\n\\t- 'pcm'\\n\\t- 'pt'\\n\\t- 'sw'\\n\\t- 'yo'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2qcCQnU8dgQ"
   },
   "source": [
    "##b. Train the model\n",
    "\n",
    "In the section below, we provide three options: \n",
    "\n",
    "- 1) training model without any validation; \n",
    "- 2) training model with validation but without testing; \n",
    "- 3) training a model with validation and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fEw-qcEhYnx"
   },
   "source": [
    "###Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sE22Nmnx9lf1"
   },
   "source": [
    "\n",
    "\n",
    "####Starter Code: Datasets, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 19003,
     "status": "ok",
     "timestamp": 1666879952672,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "ERP2sja3i3uQ",
    "outputId": "730084f3-6cde-4ef4-a638-861aed0addea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7feaa01348b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import warnings\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "from datasets import Features, Value, ClassLabel, load_dataset, Dataset\n",
    "\n",
    "require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/text-classification/requirements.txt\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "\n",
    "\n",
    "np.random.seed(420)\n",
    "torch.manual_seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1666879952673,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "2k6XKSygMnT4",
    "outputId": "debd529a-c939-47d6-ae2c-60dd40430f4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/thomas/afrisent/afrisent-semeval-2023/SubtaskA/train'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EJPw829sIRY3"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(TRAINING_DATA_DIR, 'splitted-train-dev-test', LANGUAGE_CODE)\n",
    "EVAL_DIR = os.path.join(PROJECT_DIR, TASK, 'dev')\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'models', LANGUAGE_CODE + '_no_eval')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUMBER_OF_TRAINING_EPOCHS,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    overwrite_output_dir=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "60upFv0znHN5"
   },
   "outputs": [],
   "source": [
    "data_args = SimpleNamespace(**{\n",
    "    'max_seq_length': MAXIMUM_SEQUENCE_LENGTH,\n",
    "    'overwrite_cache': False,\n",
    "    'pad_to_max_length': True,\n",
    "    'max_train_samples': None,\n",
    "    'max_eval_samples': None,\n",
    "    'max_predict_samples': None\n",
    "})\n",
    "\n",
    "model_args = SimpleNamespace(**{\n",
    "    'model_name_or_path': MODEL_NAME_OR_PATH,\n",
    "    'config_name': None,\n",
    "    'tokenizer_name': None,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'eval_dir': EVAL_DIR,\n",
    "    'cache_dir': None,\n",
    "    'do_lower_case': None,\n",
    "    'use_fast_tokenizer': True,\n",
    "    'model_revision': 'main',\n",
    "    'use_auth_token': False,\n",
    "    'ignore_mismatched_sizes': False\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2Nx63rcbnHXy"
   },
   "outputs": [],
   "source": [
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "# parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "# model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "# Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n",
    "# information sent is the one passed as arguments along with your Python/PyTorch versions.\n",
    "#send_example_telemetry(\"run_xnli\", model_args)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "log_level = 0 #training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1666879952910,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "yGlFrGztnhVX",
    "outputId": "52cf93f7-869b-4240-dd91-546daaa57a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/30/2022 04:27:21 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "# Detecting last checkpoint.\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None:\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1666879952911,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "ZSh2DwJzM_cI",
    "outputId": "326b1c0d-2cd5-4516-a142-7e0342714bd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGUAGE_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1666883839778,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "hZc-mzkXnhdF",
    "outputId": "06e5bc16-fd84-4c40-f720-3558328f4fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'negative', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# Set seed before initializing model.\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "# In distributed training, the load_dataset function guarantees that only one local process can concurrently\n",
    "# download the dataset.\n",
    "# Downloading and loading xnli dataset from the hub.\n",
    "\n",
    "\n",
    "if training_args.do_train:\n",
    "\n",
    "    #train_dataset = load_dataset('csv', data_files={'train': model_args.data_dir + '/train.csv'}, cache_dir=model_args.cache_dir)\n",
    "    #df = train_dataset[\"train\"].to_pandas()\n",
    "    #label_list = df['label'].unique().tolist()\n",
    "    #label_list = train_dataset.features[\"label\"].names\n",
    "    df = pd.read_csv(model_args.data_dir + '/train.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    train_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "if training_args.do_eval:\n",
    "    #eval_dataset = load_dataset('csv', data_files={'validation': model_args.data_dir + '/dev.csv'}, cache_dir=model_args.cache_dir)\n",
    "\n",
    "    #df = eval_dataset[\"validation\"].to_pandas()\n",
    "    #label_list = df['label'].unique().tolist()\n",
    "    #label_list = eval_dataset.features[\"label\"].names\n",
    "    df = pd.read_csv(model_args.data_dir + '/dev.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    eval_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "if training_args.do_predict:\n",
    "    #predict_dataset = load_dataset('csv', data_files={'test': model_args.data_dir + '/test.csv'}, cache_dir=model_args.cache_dir)\n",
    "\n",
    "    #df = predict_dataset[\"test\"].to_pandas()\n",
    "    #label_list = df['label'].unique().tolist()\n",
    "    #label_list = predict_dataset.features[\"label\"].names\n",
    "    df = pd.read_csv(model_args.data_dir + '/test.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    predict_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "# Labels\n",
    "num_labels = len(label_list)\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9gxi4Ll-HFQ"
   },
   "source": [
    "####Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6173,
     "status": "ok",
     "timestamp": 1666883849304,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "pd_l2PG3nhiY",
    "outputId": "5753544f-0e2b-489c-edfc-1014449d4170"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:2596] 2022-10-30 04:27:24,087 >> Some weights of the model checkpoint at Davlan/afro-xlmr-mini were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:2608] 2022-10-30 04:27:24,088 >> Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-mini and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "# In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab.\n",
    "#         finetuning_task=\"xnli\",\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    do_lower_case=model_args.do_lower_case,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    use_fast=model_args.use_fast_tokenizer,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    "    ignore_mismatched_sizes=model_args.ignore_mismatched_sizes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1666883849305,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "slMaLbYvnHmP",
    "outputId": "7c6e8b47-3511-42b8-a689-317cd74f3190"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def preprocess_function(examples):\\n    # Tokenize the texts\\n    return tokenizer(\\n        examples[\"premise\"],\\n        examples[\"hypothesis\"],\\n        padding=padding,\\n        max_length=data_args.max_seq_length,\\n        truncation=True,\\n    )\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the datasets\n",
    "# Padding strategy\n",
    "if data_args.pad_to_max_length:\n",
    "    padding = \"max_length\"\n",
    "else:\n",
    "    # We will pad later, dynamically at batch creation, to the max sequence length in each batch\n",
    "    padding = False\n",
    "\n",
    "# Some models have set the order of the labels to use, so let's make sure we do use it.\n",
    "label_to_id = None\n",
    "label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "\n",
    "if label_to_id is not None:\n",
    "    model.config.label2id = label_to_id\n",
    "    model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "\n",
    "'''\n",
    "    def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    return tokenizer(\n",
    "        examples[\"premise\"],\n",
    "        examples[\"hypothesis\"],\n",
    "        padding=padding,\n",
    "        max_length=data_args.max_seq_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 21194,
     "status": "ok",
     "timestamp": 1666883870487,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "gKAQ2leboGN3",
    "outputId": "4d40c5b1-5009-4979-cf98-dfbbd898627e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878f4549aeb44185882f7b2557b6c29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925296b2995849b2a1225a3e37950485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    #print\n",
    "    texts =(examples['text'],)\n",
    "    result = tokenizer(*texts, padding=padding, max_length=data_args.max_seq_length, truncation=True)\n",
    "    #print(examples['text'])\n",
    "    #result = tokenizer(examples['text'], examples['text'], padding=padding, max_length=data_args.max_seq_length, truncation=True)\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    \n",
    "    result['length'], result[\"tokenized\"] = [], []\n",
    "    for input_ids in result['input_ids']:\n",
    "        toks = tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=True)\n",
    "        result['length'].append(len(toks)+2)\n",
    "        result['tokenized'].append(' '.join(toks))\n",
    "    return result\n",
    "\n",
    "if training_args.do_train:\n",
    "    if data_args.max_train_samples is not None:\n",
    "        max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
    "        train_dataset = train_dataset.select(range(max_train_samples))\n",
    "    with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "        train_dataset = train_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on train dataset\",\n",
    "        )\n",
    "    # Log a few random samples from the training set:\n",
    "    for index in random.sample(range(len(train_dataset)), 3):\n",
    "        logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "\n",
    "if training_args.do_eval:\n",
    "    if data_args.max_eval_samples is not None:\n",
    "        max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
    "        eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
    "    with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "        eval_dataset = eval_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on validation dataset\",\n",
    "        )\n",
    "\n",
    "if training_args.do_predict:\n",
    "    if data_args.max_predict_samples is not None:\n",
    "        max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n",
    "        predict_dataset = predict_dataset.select(range(max_predict_samples))\n",
    "    with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n",
    "        predict_dataset = predict_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on prediction dataset\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1666883921333,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "6Hi6VwK5O1ve",
    "outputId": "1d30958b-4b3d-409f-e9c2-97f9fb4a07f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask', 'length', 'tokenized'],\n",
       "     num_rows: 5965\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask', 'length', 'tokenized'],\n",
       "     num_rows: 852\n",
       " }))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6EnnkjSTKk4-"
   },
   "outputs": [],
   "source": [
    "train_text, train_labels = train_dataset['tokenized'], train_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "tNt_9ZMsKnr8"
   },
   "outputs": [],
   "source": [
    "eval_text, eval_labels = eval_dataset['tokenized'], eval_dataset['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lEqGqVv-TgQ"
   },
   "source": [
    "#### Simple Baselines\n",
    "\n",
    "Class Proportions (AKA Constant / Majority Classifier Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1666880047283,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "pIsze7tckrbK",
    "outputId": "26a838cf-00c6-4df3-f1e4-70d79c5c7c83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38028169014084506 0.5510204081632654\n",
      "0.2511737089201878 0.401500938086304\n",
      "0.3685446009389671 0.5385934819897085\n"
     ]
    }
   ],
   "source": [
    "for l in np.unique(eval_labels):\n",
    "  print(np.mean(np.array(eval_labels) == l), f1_score([l] * len(eval_labels), eval_labels, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2cmGwea_KtrM"
   },
   "outputs": [],
   "source": [
    "# set up unigram, bigram, trigram BOW and TF-IDF\n",
    "\n",
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=100000, min_df=7, max_df=0.8)\n",
    "unigram_vectorizer.fit(train_text)\n",
    "X_train_unigram = unigram_vectorizer.transform(train_text)\n",
    "X_test_unigram = unigram_vectorizer.transform(eval_text)\n",
    "\n",
    "unigram_tf_idf_transformer = TfidfTransformer()\n",
    "unigram_tf_idf_transformer.fit(X_train_unigram)\n",
    "X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)\n",
    "X_test_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_test_unigram)\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=100000, min_df=7, max_df=0.8)\n",
    "bigram_vectorizer.fit(train_text)\n",
    "X_train_bigram = bigram_vectorizer.transform(train_text)\n",
    "X_test_bigram = bigram_vectorizer.transform(eval_text)\n",
    "\n",
    "bigram_tf_idf_transformer = TfidfTransformer()\n",
    "bigram_tf_idf_transformer.fit(X_train_bigram)\n",
    "X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)\n",
    "X_test_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_test_bigram)\n",
    "\n",
    "trigram_vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=100000, min_df=7, max_df=0.8)\n",
    "trigram_vectorizer.fit(train_text)\n",
    "X_train_trigram = trigram_vectorizer.transform(train_text)\n",
    "X_test_trigram = trigram_vectorizer.transform(eval_text)\n",
    "trigram_tf_idf_transformer = TfidfTransformer()\n",
    "trigram_tf_idf_transformer.fit(X_train_trigram)\n",
    "X_train_trigram_tf_idf =trigram_tf_idf_transformer.transform(X_train_trigram)\n",
    "X_test_trigram_tf_idf =trigram_tf_idf_transformer.transform(X_test_trigram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "RArsspQ1HelL"
   },
   "outputs": [],
   "source": [
    "def AdaDTC(**params):\n",
    "    base_params = {}\n",
    "    for k, v in list(params.items()):\n",
    "        if k[:16] == 'base_estimator__':\n",
    "            base_params[k[16:]] = v\n",
    "            del params[k]\n",
    "    return AdaBoostClassifier(base_estimator=DecisionTreeClassifier(**base_params), **params)\n",
    "\n",
    "classifiers = [\n",
    "    (MultinomialNB, [\n",
    "        {'alpha': 1e-3}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 1e3},\n",
    "    ]), \n",
    "    (SVC, [\n",
    "        {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000},\n",
    "        {'C': 1000.0, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 1000}\n",
    "    ]), \n",
    "    (LogisticRegression, [\n",
    "        {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "    ]), \n",
    "    (RandomForestClassifier, [\n",
    "        {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
    "    ]), \n",
    "    (AdaDTC, [\n",
    "        {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 10, \n",
    "          'base_estimator__splitter': 'best', 'learning_rate': 0.1, 'n_estimators': 200},\n",
    "        {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, \n",
    "         'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
    "    ]),  \n",
    "    (MLPClassifier, [\n",
    "        {'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
    "    ])\n",
    "    ]\n",
    "\n",
    "X_train_data = {'unigram counts': X_train_unigram,\n",
    "                'unigram tf-idf': X_train_unigram_tf_idf,\n",
    "                'bigram counts': X_train_bigram, \n",
    "                'bigram tf-idf': X_train_bigram_tf_idf,\n",
    "                'trigram counts': X_train_trigram, \n",
    "                'trigram tf-idf': X_train_trigram_tf_idf}\n",
    "\n",
    "X_test_data = {'unigram counts': X_test_unigram,\n",
    "                'unigram tf-idf': X_test_unigram_tf_idf,\n",
    "                'bigram counts': X_test_bigram, \n",
    "                'bigram tf-idf': X_test_bigram_tf_idf,\n",
    "                'trigram counts': X_test_trigram, \n",
    "                'trigram tf-idf': X_test_trigram_tf_idf}\n",
    "\n",
    "def train_and_show_scores(title, model, parameters):\n",
    "\n",
    "    X_train, X_test = X_train_data[title], X_test_data[title]\n",
    "    y_train, y_test = train_labels, eval_labels\n",
    "    \n",
    "    \n",
    "    best_train, best_test, best_f1, best_params = 0, 0, 0, None\n",
    "    for params in parameters:\n",
    "        clf = model(**params)\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.simplefilter(\"always\")\n",
    "            clf.fit(X_train, y_train)\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "        test_f1 = f1_score(clf.predict(X_test), y_test, average='weighted')\n",
    "        \n",
    "        if test_f1 > best_f1:\n",
    "            best_train, best_test, best_f1, best_params = train_score, test_score, test_f1, params\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    {title}\n",
    "    Train score: {best_train:.3}\n",
    "    Eval score: {best_test:.3}\n",
    "    Weighted Test F1: {best_f1:.3}\n",
    "    Params: {best_params}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "executionInfo": {
     "elapsed": 3962,
     "status": "error",
     "timestamp": 1666880576651,
     "user": {
      "displayName": "Thomas Lu",
      "userId": "07958275653434804774"
     },
     "user_tz": 240
    },
    "id": "6vktvdutUZm9",
    "outputId": "02534ad2-58fd-4c56-e73c-5b355a41ef28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "\n",
      "    unigram counts\n",
      "    Train score: 0.69\n",
      "    Eval score: 0.602\n",
      "    Weighted Test F1: 0.61\n",
      "    Params: {'alpha': 1}\n",
      "    \n",
      "\n",
      "    unigram tf-idf\n",
      "    Train score: 0.672\n",
      "    Eval score: 0.588\n",
      "    Weighted Test F1: 0.629\n",
      "    Params: {'alpha': 1}\n",
      "    \n",
      "\n",
      "    bigram counts\n",
      "    Train score: 0.765\n",
      "    Eval score: 0.643\n",
      "    Weighted Test F1: 0.646\n",
      "    Params: {'alpha': 0.1}\n",
      "    \n",
      "\n",
      "    bigram tf-idf\n",
      "    Train score: 0.718\n",
      "    Eval score: 0.616\n",
      "    Weighted Test F1: 0.655\n",
      "    Params: {'alpha': 1}\n",
      "    \n",
      "\n",
      "    trigram counts\n",
      "    Train score: 0.74\n",
      "    Eval score: 0.644\n",
      "    Weighted Test F1: 0.648\n",
      "    Params: {'alpha': 1}\n",
      "    \n",
      "\n",
      "    trigram tf-idf\n",
      "    Train score: 0.72\n",
      "    Eval score: 0.613\n",
      "    Weighted Test F1: 0.65\n",
      "    Params: {'alpha': 1}\n",
      "    \n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "\n",
      "    unigram counts\n",
      "    Train score: 0.873\n",
      "    Eval score: 0.617\n",
      "    Weighted Test F1: 0.63\n",
      "    Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
      "    \n",
      "\n",
      "    unigram tf-idf\n",
      "    Train score: 0.97\n",
      "    Eval score: 0.641\n",
      "    Weighted Test F1: 0.652\n",
      "    Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
      "    \n",
      "\n",
      "    bigram counts\n",
      "    Train score: 0.917\n",
      "    Eval score: 0.644\n",
      "    Weighted Test F1: 0.655\n",
      "    Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
      "    \n",
      "\n",
      "    bigram tf-idf\n",
      "    Train score: 0.988\n",
      "    Eval score: 0.648\n",
      "    Weighted Test F1: 0.66\n",
      "    Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
      "    \n",
      "\n",
      "    trigram counts\n",
      "    Train score: 0.923\n",
      "    Eval score: 0.634\n",
      "    Weighted Test F1: 0.648\n",
      "    Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
      "    \n",
      "\n",
      "    trigram tf-idf\n",
      "    Train score: 0.987\n",
      "    Eval score: 0.643\n",
      "    Weighted Test F1: 0.653\n",
      "    Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000}\n",
      "    \n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "\n",
      "    unigram counts\n",
      "    Train score: 0.798\n",
      "    Eval score: 0.594\n",
      "    Weighted Test F1: 0.603\n",
      "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "    \n",
      "\n",
      "    unigram tf-idf\n",
      "    Train score: 0.745\n",
      "    Eval score: 0.621\n",
      "    Weighted Test F1: 0.634\n",
      "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "    \n",
      "\n",
      "    bigram counts\n",
      "    Train score: 0.963\n",
      "    Eval score: 0.64\n",
      "    Weighted Test F1: 0.648\n",
      "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "    \n",
      "\n",
      "    bigram tf-idf\n",
      "    Train score: 0.813\n",
      "    Eval score: 0.656\n",
      "    Weighted Test F1: 0.669\n",
      "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "    \n",
      "\n",
      "    trigram counts\n",
      "    Train score: 0.97\n",
      "    Eval score: 0.637\n",
      "    Weighted Test F1: 0.645\n",
      "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "    \n",
      "\n",
      "    trigram tf-idf\n",
      "    Train score: 0.817\n",
      "    Eval score: 0.653\n",
      "    Weighted Test F1: 0.666\n",
      "    Params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "    \n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "\n",
      "    unigram counts\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.604\n",
      "    Weighted Test F1: 0.648\n",
      "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
      "    \n",
      "\n",
      "    unigram tf-idf\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.596\n",
      "    Weighted Test F1: 0.637\n",
      "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
      "    \n",
      "\n",
      "    bigram counts\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.599\n",
      "    Weighted Test F1: 0.643\n",
      "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
      "    \n",
      "\n",
      "    bigram tf-idf\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.592\n",
      "    Weighted Test F1: 0.639\n",
      "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
      "    \n",
      "\n",
      "    trigram counts\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.592\n",
      "    Weighted Test F1: 0.634\n",
      "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
      "    \n",
      "\n",
      "    trigram tf-idf\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.595\n",
      "    Weighted Test F1: 0.649\n",
      "    Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 500}\n",
      "    \n",
      "<function AdaDTC at 0x7fea63a071f0>\n",
      "\n",
      "    unigram counts\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.562\n",
      "    Weighted Test F1: 0.579\n",
      "    Params: {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 10, 'base_estimator__splitter': 'best', 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "    \n",
      "\n",
      "    unigram tf-idf\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.553\n",
      "    Weighted Test F1: 0.577\n",
      "    Params: {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 10, 'base_estimator__splitter': 'best', 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "    \n",
      "\n",
      "    bigram counts\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.562\n",
      "    Weighted Test F1: 0.579\n",
      "    Params: {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 10, 'base_estimator__splitter': 'best', 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "    \n",
      "\n",
      "    bigram tf-idf\n",
      "    Train score: 1.0\n",
      "    Eval score: 0.56\n",
      "    Weighted Test F1: 0.586\n",
      "    Params: {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 10, 'base_estimator__splitter': 'best', 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "    \n",
      "\n",
      "    trigram counts\n",
      "    Train score: 0.846\n",
      "    Eval score: 0.577\n",
      "    Weighted Test F1: 0.587\n",
      "    Params: {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
      "    \n",
      "\n",
      "    trigram tf-idf\n",
      "    Train score: 0.86\n",
      "    Eval score: 0.582\n",
      "    Weighted Test F1: 0.594\n",
      "    Params: {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__splitter': 'random', 'learning_rate': 1, 'n_estimators': 200}\n",
      "    \n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "\n",
      "    unigram counts\n",
      "    Train score: 0.956\n",
      "    Eval score: 0.64\n",
      "    Weighted Test F1: 0.649\n",
      "    Params: {'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "    \n",
      "\n",
      "    unigram tf-idf\n",
      "    Train score: 0.712\n",
      "    Eval score: 0.602\n",
      "    Weighted Test F1: 0.627\n",
      "    Params: {'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "    \n",
      "\n",
      "    bigram counts\n",
      "    Train score: 0.985\n",
      "    Eval score: 0.658\n",
      "    Weighted Test F1: 0.67\n",
      "    Params: {'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "    \n",
      "\n",
      "    bigram tf-idf\n",
      "    Train score: 0.784\n",
      "    Eval score: 0.65\n",
      "    Weighted Test F1: 0.667\n",
      "    Params: {'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "    \n",
      "\n",
      "    trigram counts\n",
      "    Train score: 0.984\n",
      "    Eval score: 0.638\n",
      "    Weighted Test F1: 0.646\n",
      "    Params: {'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "    \n",
      "\n",
      "    trigram tf-idf\n",
      "    Train score: 0.786\n",
      "    Eval score: 0.653\n",
      "    Weighted Test F1: 0.67\n",
      "    Params: {'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Get scores for multiple different models\n",
    "for model, parameters in classifiers:\n",
    "    print(model)\n",
    "    train_and_show_scores('unigram counts', model, parameters)\n",
    "    train_and_show_scores('unigram tf-idf', model, parameters)\n",
    "    train_and_show_scores('bigram counts', model, parameters)\n",
    "    train_and_show_scores('bigram tf-idf', model, parameters)\n",
    "    train_and_show_scores('trigram counts', model, parameters)\n",
    "    train_and_show_scores('trigram tf-idf', model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "piucart2uCIl"
   },
   "outputs": [],
   "source": [
    "# Clear Memory\n",
    "del unigram_vectorizer\n",
    "del X_train_unigram \n",
    "del X_test_unigram\n",
    "\n",
    "del unigram_tf_idf_transformer\n",
    "del X_train_unigram_tf_idf\n",
    "del X_test_unigram_tf_idf\n",
    "                                                             \n",
    "del bigram_vectorizer\n",
    "del X_train_bigram\n",
    "del X_test_bigram\n",
    "\n",
    "del bigram_tf_idf_transformer\n",
    "del X_train_bigram_tf_idf\n",
    "del X_test_bigram_tf_idf\n",
    "\n",
    "del trigram_vectorizer\n",
    "del X_train_trigram\n",
    "del X_test_trigram\n",
    "\n",
    "del trigram_tf_idf_transformer\n",
    "del X_train_trigram_tf_idf\n",
    "del X_test_trigram_tf_idf\n",
    "\n",
    "del X_train_data\n",
    "del X_test_data \n",
    "\n",
    "del train_text\n",
    "del eval_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fi_pJl3N9RcT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d203a7fbe37afbb990fedfc21c321928443618f3d7b991e0237ff71906aa031f"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "008a7cb40017467b8d4450e52e0c3ec5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2691cee6ebda4659afdc7afc3d7c3ccf",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d96193cb0ef436987f37d611e0c3c23",
      "value": 9
     }
    },
    "01bbb58eeced4ed4920756d513870c5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08e3f965a5ea4b338aba411dbb969ec6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c8da5d1f22f4f2990196f1d1164dc72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1193886e44d94cc9927d05680e26348d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edd1fc29c36a4beda3528a5b962d5d4e",
      "placeholder": "",
      "style": "IPY_MODEL_508778f87d1a4733a86bc7466ce6c689",
      "value": " 9/10 [00:18&lt;00:01,  1.89s/ba]"
     }
    },
    "1d96193cb0ef436987f37d611e0c3c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2048f8794fef499cb0757fad16437a92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c8da5d1f22f4f2990196f1d1164dc72",
      "placeholder": "",
      "style": "IPY_MODEL_47c11996d2f142779998e1ce52519e62",
      "value": " 1/2 [00:02&lt;00:01,  1.86s/ba]"
     }
    },
    "2691cee6ebda4659afdc7afc3d7c3ccf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "426e41f07cb145408a12146dff293ad6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b31b9c1562a4505bd84039e344eb03a",
      "placeholder": "",
      "style": "IPY_MODEL_ac7711f32d374b74b6f7949db6d2cb94",
      "value": "Running tokenizer on validation dataset:  50%"
     }
    },
    "47c11996d2f142779998e1ce52519e62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b31b9c1562a4505bd84039e344eb03a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e6edbccc9224ba89714e6d0e67fe76e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aafb2c69887549648e9c7044d6a344f3",
       "IPY_MODEL_008a7cb40017467b8d4450e52e0c3ec5",
       "IPY_MODEL_1193886e44d94cc9927d05680e26348d"
      ],
      "layout": "IPY_MODEL_01bbb58eeced4ed4920756d513870c5f"
     }
    },
    "508778f87d1a4733a86bc7466ce6c689": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e01536f748a4689b0c1ab32258b0161": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "865bc4814f3742cdb1d2230f141a8e72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e01536f748a4689b0c1ab32258b0161",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6cc64f17d074ff68cced49559981438",
      "value": 1
     }
    },
    "877d1854199e4362877dd8774f10bc23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_426e41f07cb145408a12146dff293ad6",
       "IPY_MODEL_865bc4814f3742cdb1d2230f141a8e72",
       "IPY_MODEL_2048f8794fef499cb0757fad16437a92"
      ],
      "layout": "IPY_MODEL_92b9d2b9889a4d92a3907c5791df3091"
     }
    },
    "92b9d2b9889a4d92a3907c5791df3091": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aafb2c69887549648e9c7044d6a344f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08e3f965a5ea4b338aba411dbb969ec6",
      "placeholder": "",
      "style": "IPY_MODEL_b4943d26f11e46358a64ca534efade84",
      "value": "Running tokenizer on train dataset:  90%"
     }
    },
    "ac7711f32d374b74b6f7949db6d2cb94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4943d26f11e46358a64ca534efade84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edd1fc29c36a4beda3528a5b962d5d4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6cc64f17d074ff68cced49559981438": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
